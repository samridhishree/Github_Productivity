"rectype","issueid","project_owner","project_name","actor","time","text","action","title"
"issue_title","1327","nilearn","nilearn","AlexandreAbraham","2016-11-14 10:56:03","It seems that we cannot host files anymore on NITRC. This is critical as most of the datasets are hosted there. Plus, NITRC does not return a 404 error, meaning that nilearn thinks it downloads the correct files but explodes afterward.

Plan of action:
- First, update nilearn to add basic checks after download: either specify the size explicetely, or a hash, or simply check that binary files do not start with <html>
- Then, upload the files on another hosting service and update all the links
- Finally, implement something to force nilearn downloading the data again if a new version is available (here, the new version will be the one hosted elsewhere). This is something already asked for neurovault fetcher so it is not orthogonal to nilearn's roadmap.","start issue","All NITRC files are gone"
"issue_closed","1327","nilearn","nilearn","AlexandreAbraham","2016-12-22 06:33:31","","closed issue","All NITRC files are gone"
"issue_comment","1327","nilearn","nilearn","AlexandreAbraham","2016-11-14 12:51:56","Fiou, I'm relieved :P.

Small check passed for me. For people having problem: you can clear the nilearn_data directory (sorry for the inconvenience).
","",""
"issue_comment","1327","nilearn","nilearn","GaelVaroquaux","2016-11-14 12:39:15","I think that I've fixed the problem. It was a configuration switch to flip in the NITRC set up (disable the external downloads).

Everything should be working now. Could people check (I did a small check myself).
","",""
"issue_comment","1327","nilearn","nilearn","salma1601","2016-11-14 18:33:42","`fetch_oasis_vbm` works OK for me now. Thanks
","",""
