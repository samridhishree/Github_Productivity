"rectype","issueid","project_owner","project_name","actor","time","text","action","title"
"issue_title","536","nilearn","nilearn","banilo","2015-04-10 17:01:06","","start issue","[WIP] Use iterators for check_niimg* and concat_niimgs"
"issue_closed","536","nilearn","nilearn","AlexandreAbraham","2015-04-15 08:34:32","","closed issue","[WIP] Use iterators for check_niimg* and concat_niimgs"
"pull_request_title","536","nilearn","nilearn","banilo","2015-04-10 17:01:06","","54d9e71c8b29d23f7df6e6b14a5b9d16420aad44","[WIP] Use iterators for check_niimg* and concat_niimgs"
"issue_comment","536","nilearn","nilearn","AlexandreAbraham","2015-04-13 08:35:52","@banilo, the behavior should be like this:
- if data is not loaded (ie filenames), then we browse the list and get the lengths of the files (it is costless because we only read the header of the file). Then we preallocate a big numpy array: this saves memory and is faster.
- if the data is loaded, then we can also browse and get the length since it's already in memory.
- if the data given is a generator (meaning that we can browse it only once), then we should put the images in a list and concatenate them afterwards.

Does that answer your question? I can see in the code that you removed all the logic of memory pre-allocation. This is not what we want.
","",""
"issue_comment","536","nilearn","nilearn","AlexandreAbraham","2015-04-15 08:34:32","Replaced by #542.
","",""
"pull_request_commit","536","nilearn","nilearn","AlexandreAbraham","2015-04-08 14:07:31","Refactor check_niimg (again, more final version)","416453dba7e811e333f2269091fb89c829f9cfdd",""
"pull_request_commit","536","nilearn","nilearn","AlexandreAbraham","2015-04-08 14:14:12","Move code","f4a67b9578dec932ba117fb9493c1dafaa1ae515",""
"pull_request_commit","536","nilearn","nilearn","banilo","2015-04-10 16:59:32","concat_niimgs uses iterator","54d9e71c8b29d23f7df6e6b14a5b9d16420aad44",""
