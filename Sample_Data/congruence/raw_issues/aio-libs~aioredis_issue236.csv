"rectype","issueid","project_owner","project_name","actor","time","text","action","title"
"issue_title","236","aio-libs","aioredis","argaen","2017-05-26 22:09:44","When finishing executing tests or any program that uses aioredis, it usually shows 

```
2017-05-26 23:56:44,614 ERROR asyncio(1148) | Task was destroyed but it is pending!
task: <Task pending coro=<RedisPool._do_close() running at /home/blck/.pyenv/versions/3.5.2/envs/aiocache/lib/python3.5/site-packages/aioredis/pool.py:117> wait_for=<Future pending cb=[Task._wakeup()]>>
```

This is basically because the pool wasn't closed before exiting and the task is still pending (https://github.com/aio-libs/aioredis/blob/master/aioredis/pool.py#L82).

This warning still appears even when all connections in the pool are closed (because someone called `clear` or because there are no connections). IMO the warning should appear only when the program exits while there were resources allocated (i.e. connections) rather than doing it by default.

Are you OK if I provide a MR fixing that?","start issue","Pool not closed warning"
"issue_closed","236","aio-libs","aioredis","popravich","2017-06-08 20:27:48","","closed issue","Pool not closed warning"
"issue_comment","236","aio-libs","aioredis","popravich","2017-05-31 19:04:37","Oh, I can't remember why I made it work this way, I guess there was a reason for this.
Currently when pool is created it starts async task waiting for ""close"" event to be set and
close & drop all connections (including connections in use).
I think this can be fixed to only set event flag and start this task from `close()` method.","",""
"issue_comment","236","aio-libs","aioredis","argaen","2017-06-01 07:34:50","Yup, that was my intention. I'll provide a MR with the changes","",""
"issue_comment","236","aio-libs","aioredis","popravich","2017-06-01 07:35:53","ok","",""
