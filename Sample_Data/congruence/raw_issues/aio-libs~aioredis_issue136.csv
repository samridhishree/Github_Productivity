"rectype","issueid","project_owner","project_name","actor","time","text","action","title"
"issue_title","136","aio-libs","aioredis","cynecx","2016-08-14 19:46:48","This patch closes the RedisPool when the connection to the redis server has failed. We would get an asyncio error when closing the event loop:

```
Task was destroyed but it is pending!
task: <Task pending coro=<RedisPool._do_close() running at python3.5/site-packages/aioredis/pool.py:102> wait_for=<Future pending cb=[Task._wakeup()]>>
```
","start issue","Close RedisPool when connection to the redis server has failed (To prevent asyncio lock)"
"issue_closed","136","aio-libs","aioredis","popravich","2016-08-22 07:42:37","","closed issue","Close RedisPool when connection to the redis server has failed (To prevent asyncio lock)"
"pull_request_title","136","aio-libs","aioredis","cynecx","2016-08-14 19:46:48","This patch closes the RedisPool when the connection to the redis server has failed. We would get an asyncio error when closing the event loop:

```
Task was destroyed but it is pending!
task: <Task pending coro=<RedisPool._do_close() running at python3.5/site-packages/aioredis/pool.py:102> wait_for=<Future pending cb=[Task._wakeup()]>>
```
","10756dfa46d46f796a4cb5b03d2b3ad0356903a6","Close RedisPool when connection to the redis server has failed (To prevent asyncio lock)"
"pull_request_merged","136","aio-libs","aioredis","popravich","2016-08-22 07:42:37","Close RedisPool when connection to the redis server has failed (To prevent asyncio lock)","62a64e58ad5b6f3554574c1e4c5c2d17c37c4867","Pull request merge from cynecx/aioredis:fix_pool to aio-libs/aioredis:master"
"issue_comment","136","aio-libs","aioredis","popravich","2016-08-15 06:52:33","Nice catch.
But, please provide a test:
try connecting to free port, catch error and check that pool is marked closed
","",""
"issue_comment","136","aio-libs","aioredis","cynecx","2016-08-15 19:17:00","@popravich Wait, I am not sure how to test this as `create_pool` raises an exception when the connection has failed, so it wouldn't return an instance of `RedisPool`. Hence there is no way to check if the pool is marked closed.

Another approach would be to catch exceptions and return the current state of pool.
But by doing this, no exceptions will be thrown which is bad in my opinion.

My last idea is to include the current pool instance into the exception object so when an exception occurs, one can ""reuse"" the pool instance which should be marked closed by create_pool.
","",""
"issue_comment","136","aio-libs","aioredis","popravich","2016-08-16 07:33:19","Yeah, missed that issue)
Lets do the following:
- add `logger.debug` call after `gather` in `_do_close()` with something like this
  `logger.debug(""Closed %d connections"", len(waiters))`
- in test try connecting to unused port
- catch exception
- run dummy loop iteration (so that `_do_closed()` finish)
- catch that log message
  So we'll be sure that coroutine is done.
","",""
"issue_comment","136","aio-libs","aioredis","cynecx","2016-08-17 19:27:57","@popravich Isn't this a little bit inefficient to check? I mean, can't we simply check if the event loop tasks are marked done?.  Something like:

```
# ... create pool -> close

for task in asyncio.Task.all_tasks(loop):
    assert(task.done()) # All tasks should be ""done"" if the pool is successfully marked closed
```
","",""
"issue_comment","136","aio-libs","aioredis","popravich","2016-08-18 07:06:58","@cynecx this won't work as test itself is a task and is not done until test coroutine is ended.
With logging we'd be able to make even more complex test, for instance start redis server with `maxclients=1` and try to create pool with `min=2` and catch logs saying that 1 connection has been closed on that error
","",""
"issue_comment","136","aio-libs","aioredis","cynecx","2016-08-19 19:01:26","@popravich Can you review the latest commit. As a asyncio beginner I wasn't sure how to run a loop iteration while being in a loop, so I figured out using `asyncio.sleep` which seems hacky...
Also I wasn't sure how to catch debug messages, so I went with a logging handler.
","",""
"issue_comment","136","aio-libs","aioredis","coveralls","2016-08-19 19:05:05","[![Coverage Status](https://coveralls.io/builds/7528305/badge)](https://coveralls.io/builds/7528305)

Coverage decreased (-0.04%) to 97.219% when pulling **2083f650091d702e5f816b2d5953103f7d5ff7b3 on cynecx:fix_pool** into **170f02538fcafd6616e702a9aa73ff7b689cbb59 on aio-libs:master**.
","",""
"issue_comment","136","aio-libs","aioredis","coveralls","2016-08-19 19:20:51","[![Coverage Status](https://coveralls.io/builds/7528574/badge)](https://coveralls.io/builds/7528574)

Coverage increased (+0.01%) to 97.271% when pulling **2ae6e6f0cabaa5947596b31fa1d09ce11561ec95 on cynecx:fix_pool** into **170f02538fcafd6616e702a9aa73ff7b689cbb59 on aio-libs:master**.
","",""
"issue_comment","136","aio-libs","aioredis","cynecx","2016-08-19 20:19:28","@popravich Please review the latest commit.
","",""
"issue_comment","136","aio-libs","aioredis","coveralls","2016-08-19 20:24:32","[![Coverage Status](https://coveralls.io/builds/7529602/badge)](https://coveralls.io/builds/7529602)

Coverage increased (+0.01%) to 97.269% when pulling **10756dfa46d46f796a4cb5b03d2b3ad0356903a6 on cynecx:fix_pool** into **170f02538fcafd6616e702a9aa73ff7b689cbb59 on aio-libs:master**.
","",""
"issue_comment","136","aio-libs","aioredis","coveralls","2016-08-19 20:24:32","[![Coverage Status](https://coveralls.io/builds/7529602/badge)](https://coveralls.io/builds/7529602)

Coverage increased (+0.01%) to 97.269% when pulling **10756dfa46d46f796a4cb5b03d2b3ad0356903a6 on cynecx:fix_pool** into **170f02538fcafd6616e702a9aa73ff7b689cbb59 on aio-libs:master**.
","",""
"issue_comment","136","aio-libs","aioredis","coveralls","2016-08-19 20:24:32","[![Coverage Status](https://coveralls.io/builds/7529602/badge)](https://coveralls.io/builds/7529602)

Coverage increased (+0.01%) to 97.269% when pulling **10756dfa46d46f796a4cb5b03d2b3ad0356903a6 on cynecx:fix_pool** into **170f02538fcafd6616e702a9aa73ff7b689cbb59 on aio-libs:master**.
","",""
"issue_comment","136","aio-libs","aioredis","popravich","2016-08-22 07:42:39","Looks good. Thanks
","",""
"pull_request_commit_comment","136","aio-libs","aioredis","popravich","2016-08-19 20:11:18","``` python
with pytest.raises(Exception):
    yield from create_pool(...)
```
","10756dfa46d46f796a4cb5b03d2b3ad0356903a6","(None, '', u'tests/pool_test.py')"
"pull_request_commit","136","aio-libs","aioredis","me@cynecx.net","2016-08-14 18:58:20","Close RedisPool when connection to the redis server has failed (To prevent asyncio lock)","afd4d6c7428b3ce6f6973b0e506ae9b590982082",""
"pull_request_commit","136","aio-libs","aioredis","me@cynecx.net","2016-08-19 18:58:32","Add another test for pool","2083f650091d702e5f816b2d5953103f7d5ff7b3",""
"pull_request_commit","136","aio-libs","aioredis","me@cynecx.net","2016-08-19 19:11:25","Fix converage checks (pool_test)","2ae6e6f0cabaa5947596b31fa1d09ce11561ec95",""
"pull_request_commit","136","aio-libs","aioredis","me@cynecx.net","2016-08-19 20:17:38","Use pytest.raises instead of try/except construct","10756dfa46d46f796a4cb5b03d2b3ad0356903a6",""
