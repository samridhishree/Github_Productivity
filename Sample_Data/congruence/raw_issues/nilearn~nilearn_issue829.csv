"rectype","issueid","project_owner","project_name","actor","time","text","action","title"
"issue_title","829","nilearn","nilearn","arthurmensch","2015-11-06 10:34:36","Bug #827. I force `transpose = True` for `multi_pca` to yield the same result when we put twice the same data, and if we run fit twice on the same data
","start issue","HOTFIX: multi pca reproducibility"
"issue_closed","829","nilearn","nilearn","lesteve","2015-11-06 16:02:12","","closed issue","HOTFIX: multi pca reproducibility"
"pull_request_title","829","nilearn","nilearn","arthurmensch","2015-11-06 10:34:36","Bug #827. I force `transpose = True` for `multi_pca` to yield the same result when we put twice the same data, and if we run fit twice on the same data
","7528829f4a1727caeb0d0bae671708cc549d3fb2","HOTFIX: multi pca reproducibility"
"pull_request_merged","829","nilearn","nilearn","lesteve","2015-11-06 16:02:12","HOTFIX: multi pca reproducibility","bb8197e17f47d7685032b4335efc072c526f7c95","Pull request merge from arthurmensch/nilearn:hotfix_multipca_tile to nilearn/nilearn:master"
"issue_comment","829","nilearn","nilearn","arthurmensch","2015-11-06 10:40:09","ping @GaelVaroquaux @lesteve 
","",""
"issue_comment","829","nilearn","nilearn","GaelVaroquaux","2015-11-06 10:55:45","It's  probably the transpose option that does the trick. 

How does it  affect our computational performance? 
","",""
"issue_comment","829","nilearn","nilearn","arthurmensch","2015-11-06 11:21:23","Transpose = True is default in so learn < 0.17 so no performance
regression. Transpose = False could improve perf but this can be addressed
later
Le 6 nov. 2015 11:55, ""Gael Varoquaux"" notifications@github.com a écrit :

> It's probably the transpose option that does the trick.
> 
> How does it affect our computational performance?
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/nilearn/nilearn/pull/829#issuecomment-154379847.
","",""
"issue_comment","829","nilearn","nilearn","giorgiop","2015-11-06 11:30:02","LGTM.
","",""
"issue_comment","829","nilearn","nilearn","arthurmensch","2015-11-06 15:24:00","I addressed comments
","",""
"issue_comment","829","nilearn","nilearn","GaelVaroquaux","2015-11-06 15:27:14","LGTM. + 1 for merge  once Travis is green
","",""
"issue_comment","829","nilearn","nilearn","lesteve","2015-11-06 16:02:08","Travis is green, merging, thanks a lot!

About:

> How does it affect our computational performance? 

The main effect may come from the additional power iterations rather than the transpose. 
","",""
"pull_request_commit_comment","829","nilearn","nilearn","giorgiop","2015-11-06 10:37:30","It should not be `None` in testing.
","7528829f4a1727caeb0d0bae671708cc549d3fb2","(None, '', u'nilearn/decomposition/tests/test_multi_pca.py')"
"pull_request_commit_comment","829","nilearn","nilearn","arthurmensch","2015-11-06 10:42:39","Oups !
","7528829f4a1727caeb0d0bae671708cc549d3fb2","(None, '', u'nilearn/decomposition/tests/test_multi_pca.py')"
"pull_request_commit_comment","829","nilearn","nilearn","lesteve","2015-11-06 12:24:42","Just curious is there a scikit-learn convention that dictates whether random_state should be set to None or a fixed integer by default?
","7528829f4a1727caeb0d0bae671708cc549d3fb2","(6, '', u'nilearn/decomposition/multi_pca.py')"
"pull_request_commit_comment","829","nilearn","nilearn","lesteve","2015-11-06 12:26:23","You should check exact equality of components1 and components2 (fit reproducibility, ~~don't you need to set random_state btw to achieve that?~~ edit: oops you have done that a few lines above) and almost equality for components1 and components3.
","7528829f4a1727caeb0d0bae671708cc549d3fb2","(None, '', u'nilearn/decomposition/tests/test_multi_pca.py')"
"pull_request_commit_comment","829","nilearn","nilearn","lesteve","2015-11-06 12:28:10","random**ized** SVD
","7528829f4a1727caeb0d0bae671708cc549d3fb2","(None, '', u'nilearn/decomposition/multi_pca.py')"
"pull_request_commit_comment","829","nilearn","nilearn","GaelVaroquaux","2015-11-06 12:33:45","> Just curious is there a scikit-learn convention that dictates whether
> random_state should be set to None or a fixed integer by default?

In the objects we set it to None because people expect randomness.
","7528829f4a1727caeb0d0bae671708cc549d3fb2","(6, '', u'nilearn/decomposition/multi_pca.py')"
"pull_request_commit","829","nilearn","nilearn","arthurmensch","2015-11-06 10:34:00","HOTFIX: multi pca reproducibility","d46d21b142072ae8f8a0a069f2741e6bb4d2f56b",""
"pull_request_commit","829","nilearn","nilearn","arthurmensch","2015-11-06 10:42:24","FIX: random_state=None","4973aab52d1e482a840542479827d23b0f009f8c",""
"pull_request_commit","829","nilearn","nilearn","arthurmensch","2015-11-06 15:23:08","Addressed comments","ebc6717ef9d6d89f452cd8c75e62275c4d43dcee",""
"pull_request_commit","829","nilearn","nilearn","arthurmensch","2015-11-06 15:23:39","Addressed comments","7528829f4a1727caeb0d0bae671708cc549d3fb2",""
