"rectype","issueid","project_owner","project_name","actor","time","text","action","title"
"issue_title","1065","nilearn","nilearn","cinvro","2016-03-24 18:26:06","The ADHD200 downloaded should be more explicite about the data it ships
# Original issue below

I wonder if the ADHD dataset wrapped by nilearn is normalized?  
The [group ICA example](http://nilearn.github.io/auto_examples/03_connectivity/plot_canica_resting_state.html#sphx-glr-auto-examples-03-connectivity-plot-canica-resting-state-py) apply CanICA on all 40 subjects in this ADHD dataset. 

Is that okay to do so without normalization?

Could anyone offer more infomation about this 40 subjects subset of ADHD200 dataset?
","start issue","More Info about ADHD200 Dataset "
"issue_comment","1065","nilearn","nilearn","GaelVaroquaux","2016-03-31 16:48:27","I have modified the description of this issue to turn it into a documentation issue.
","",""
"issue_comment","1065","nilearn","nilearn","GaelVaroquaux","2016-04-07 07:20:32","> May be this would help ?
> http://www.nitrc.org/plugins/mwiki/index.php/neurobureau:AthenaPipeline#
> Functional_data_preprocessing_pipeline

If that's what we are downloading, it would indeed.
","",""
"issue_comment","1065","nilearn","nilearn","AlexandreAbraham","2016-03-29 08:47:36","> I wonder if the ADHD dataset wrapped by nilearn is normalized?

Of course, it is.

> Could anyone offer more infomation about this 40 subjects subset of ADHD200 dataset?

We used a preprocessed subset of ADHD shipped by the 1000 Functional Connectome Project ftp://www.nitrc.org/fcon_1000/htdocs/indi/adhd200/sites/ADHD200_40sub_preprocessed.tgz

Maybe we should now ship the entire dataset. I'll try to get some information about why we do not do that already.
","",""
"issue_comment","1065","nilearn","nilearn","AlexandreAbraham","2016-04-07 08:02:21","> If that's what we are downloading, it would indeed.

I could not find how the 40 subjects we shipped were preprocessed.

Question I asked on the dev ML but nobody answered: why don't we ship the entire ADHD dataset?
","",""
"issue_comment","1065","nilearn","nilearn","KamalakerDadi","2016-03-29 08:08:03","``` python
from nilearn import datasets

adhd_dataset = datasets.fetch_adhd() # by default 30 subjects
print(adhd_dataset.description)
```

You can have a look at its description for more information. GroupICA example is on 30 subjects.
","",""
"issue_comment","1065","nilearn","nilearn","cinvro","2016-03-31 01:30:55","@KamalakerDadi  Thanks! I realized that after I post this issue. But I am looking for more detailed information about this dataset.
@AlexandreAbraham Thanks. It would be great if nilearn can ship the entire ADHD dataset. 
","",""
"issue_comment","1065","nilearn","nilearn","KamalakerDadi","2016-04-07 07:14:20","May be this would help ?
 http://www.nitrc.org/plugins/mwiki/index.php/neurobureau:AthenaPipeline#Functional_data_preprocessing_pipeline
","",""
"issue_comment","1065","nilearn","nilearn","souravsingh","2016-04-07 12:32:47","I would like to work on this issue.How do I start?
","",""
"issue_comment","1065","nilearn","nilearn","KamalakerDadi","2016-04-10 07:55:40","> If that's what we are downloading, it would indeed.

We are downloading from http://fcon_1000.projects.nitrc.org/indi/adhd200/sites/ and there is no exact how these are preprocessed.

> I could not find how the 40 subjects we shipped were preprocessed.

Yes, you are right. 

> why don't we ship the entire ADHD dataset?

You mean all subjects as mentioned in http://preprocessed-connectomes-project.org/adhd200/index.html
","",""
