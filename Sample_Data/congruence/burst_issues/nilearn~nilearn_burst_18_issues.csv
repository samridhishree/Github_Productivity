,rectype,issueid,project_owner,project_name,actor,time,text,action,title
0,rectype,issueid,project_owner,project_name,actor,time,text,action,title
1,issue_title,84,nilearn,nilearn,pgervais,2013-06-25 16:39:31,"The current state of logging in NiLearn is not satisfactory. To attempts at organizing something have been attempted so far: LogMixin in nifti_region.py and enclosing_scope_name() in _utils/class_inspect.py, used in BaseMasker. They go in different directions.

The present pull request is an additional attempt to get to something usable. I completely abandoned the idea of a class Mixin, because it couldn't be used in a function. Thus, emitting a user message is performed with a function: log(). I added this function in _utils/logger.py. It can be used from anywhere (function, method, or top-level). 

Typical usage in a method:

```
 logger.log(""message to the user"", verbose=self.verbose)
```

The `verbose=self.verbose` is required so far, because the function cannot get access to self.verbose directly. The main advantage is that logger.log() prepends the name of the method that the user has most likely used in her script, whatever the location of the call to log(). More precisely, if the user calls the fit() method on an estimator object, and a call to log(""message"") is performed deeper in the call stack, the user will see in the message something like ""[EstimatorClass.fit] message"". 

This behaviour is achieved in log() by walking up the call stack, finding the topmost object that inherits from BaseEstimator, and reading the class and function names therein. This is much smarter than the stack_level trick used by `enclosing_scope_name`. stack_level is still supported though, but is used as a fallback is no object has been found.

I only adapted `nifti_region.py` to the new system. Launch `plot_adhd_covariance.py` to see it in action.

I would like to have feedback before proceeding.
",start issue,New logging function
2,issue_closed,84,nilearn,nilearn,pgervais,2013-09-02 13:19:40,,closed issue,New logging function
3,pull_request_title,84,nilearn,nilearn,pgervais,2013-06-25 16:39:31,"The current state of logging in NiLearn is not satisfactory. To attempts at organizing something have been attempted so far: LogMixin in nifti_region.py and enclosing_scope_name() in _utils/class_inspect.py, used in BaseMasker. They go in different directions.

The present pull request is an additional attempt to get to something usable. I completely abandoned the idea of a class Mixin, because it couldn't be used in a function. Thus, emitting a user message is performed with a function: log(). I added this function in _utils/logger.py. It can be used from anywhere (function, method, or top-level). 

Typical usage in a method:

```
 logger.log(""message to the user"", verbose=self.verbose)
```

The `verbose=self.verbose` is required so far, because the function cannot get access to self.verbose directly. The main advantage is that logger.log() prepends the name of the method that the user has most likely used in her script, whatever the location of the call to log(). More precisely, if the user calls the fit() method on an estimator object, and a call to log(""message"") is performed deeper in the call stack, the user will see in the message something like ""[EstimatorClass.fit] message"". 

This behaviour is achieved in log() by walking up the call stack, finding the topmost object that inherits from BaseEstimator, and reading the class and function names therein. This is much smarter than the stack_level trick used by `enclosing_scope_name`. stack_level is still supported though, but is used as a fallback is no object has been found.

I only adapted `nifti_region.py` to the new system. Launch `plot_adhd_covariance.py` to see it in action.

I would like to have feedback before proceeding.
",21a9ecd7640f92c77dd0bad67ba64e366aefa3ab,New logging function
4,issue_comment,84,nilearn,nilearn,GaelVaroquaux,2013-08-01 13:10:19,"Let's:

a) Put comments in the file on the limitation of this approach

b) Merge this guy and move on
",,
5,issue_comment,84,nilearn,nilearn,GaelVaroquaux,2013-08-29 12:19:07,"Good apart from my comments.
",,
6,issue_comment,84,nilearn,nilearn,pgervais,2013-08-29 11:38:42,"I'm going to need this PR very soon. A final review would be appreciated before merging.
",,
7,issue_comment,84,nilearn,nilearn,pgervais,2013-08-29 16:20:43,"I made a lot of refactoring, corrected a bug. The code is now much clearer indeed.

@GaelVaroquaux when you have a moment, can you tell me if the tests that I added are fine for you?
",,
8,issue_comment,84,nilearn,nilearn,pgervais,2013-09-02 13:19:53,"Merged by rebasing.
",,
9,issue_comment,84,nilearn,nilearn,pgervais,2013-06-27 07:33:54,"Sorry for the size of the example, but this is currently the only one in NiLearn that can be used for such a computation (all the others are not coregistered).
",,
10,pull_request_commit_comment,84,nilearn,nilearn,GaelVaroquaux,2013-08-01 13:06:55,"We don't care about non CPython
",21a9ecd7640f92c77dd0bad67ba64e366aefa3ab,"(None, '', u'nilearn/_utils/logger.py')"
11,pull_request_commit_comment,84,nilearn,nilearn,GaelVaroquaux,2013-08-29 11:49:20,"This should be in the ""notes"" section of the docstring, at the end.
",21a9ecd7640f92c77dd0bad67ba64e366aefa3ab,"(None, '', u'nilearn/_utils/logger.py')"
12,pull_request_commit_comment,84,nilearn,nilearn,GaelVaroquaux,2013-08-29 12:04:39,"I much prefer string formatting to string algebra (+). It seems to me that you could write the few lines above using string formatting (with an if statement, and maybe a temporary string) and that it would be more readable.
",21a9ecd7640f92c77dd0bad67ba64e366aefa3ab,"(None, '', u'nilearn/_utils/logger.py')"
13,pull_request_commit_comment,84,nilearn,nilearn,GaelVaroquaux,2013-08-29 12:18:21,"Shouldn't we capture sys.stdout to do more than smoke testing?
",21a9ecd7640f92c77dd0bad67ba64e366aefa3ab,"(None, '', u'nilearn/tests/test_logger.py')"
0,rectype,issueid,project_owner,project_name,actor,time,text,action,title
1,issue_title,79,nilearn,nilearn,dohmatob,2013-06-16 20:01:29,"Added some fetchers that I've had around for a while now. Precisely, these are fetchers for:
- SPM auditory single subject (lagacy dataset, bad quality, but good for demos/examples)
- SPM Multimodal fmri faces vs scrambled (I worked with @alex senior on this dataset recently)
- FSL (FEEDS single subject)
",start issue,"ENH: added fetch_spm_auditory_data(...), fetch_fsl_feeds_data(...), and ..."
2,issue_closed,79,nilearn,nilearn,pgervais,2013-08-29 11:46:44,,closed issue,"ENH: added fetch_spm_auditory_data(...), fetch_fsl_feeds_data(...), and ..."
3,pull_request_title,79,nilearn,nilearn,dohmatob,2013-06-16 20:01:29,"Added some fetchers that I've had around for a while now. Precisely, these are fetchers for:
- SPM auditory single subject (lagacy dataset, bad quality, but good for demos/examples)
- SPM Multimodal fmri faces vs scrambled (I worked with @alex senior on this dataset recently)
- FSL (FEEDS single subject)
",67ff2466d3fa33039092f0224cb59e9eb136e4af,"ENH: added fetch_spm_auditory_data(...), fetch_fsl_feeds_data(...), and ..."
4,issue_comment,79,nilearn,nilearn,GaelVaroquaux,2013-06-16 23:10:20,">   • SPM auditory single subject (lagacy dataset, bad quality, but good for
>     demos/examples)
>   • SPM Multimodal fmri faces vs scrambled (I worked with @alex senior on this
>     dataset recently)
>   • FSL (FEEDS single subject)

Can we use these in nilearn, or do these require preprocessing, or GLM
estimation that we cannot do in nilearn? If they cannot be used to write
a nilearn example, they should not be included in nilearn, but maybe
rather in pyprocess.
",,
5,issue_comment,79,nilearn,nilearn,GaelVaroquaux,2013-06-19 15:00:55,"> Yes they need preprocessing, just like NYU rest and openfmri for example.

Than they should probably go in Pypreprocess for now.
",,
6,issue_comment,79,nilearn,nilearn,pgervais,2013-08-29 11:46:39,"Since the datasets won't process themselves magically, this PR seems to be useless now. I'm closing it.
",,
7,pull_request_commit,79,nilearn,nilearn,dohmatob,2013-06-16 19:40:13,"ENH: added fetch_spm_auditory_data(...), fetch_fsl_feeds_data(...), and fetch_spm_multimodal_fmri_data(...) functions",67ff2466d3fa33039092f0224cb59e9eb136e4af,
8,pull_request_commit_comment,79,nilearn,nilearn,AlexandreAbraham,2013-06-16 20:17:05,"Is the regexp match really necessary since we already have the precise list of images ?
",67ff2466d3fa33039092f0224cb59e9eb136e4af,"(71, 1261, u'nisl/datasets.py')"
9,pull_request_commit_comment,79,nilearn,nilearn,AlexandreAbraham,2013-06-16 20:18:55,"A Reference is recommended for downloads: at least the URL of the dataset and, if relevant, the reference paper for the dataset.
",67ff2466d3fa33039092f0224cb59e9eb136e4af,"(41, 1231, u'nisl/datasets.py')"
0,rectype,issueid,project_owner,project_name,actor,time,text,action,title
1,issue_title,101,nilearn,nilearn,AlexandreAbraham,2013-09-04 07:43:25,"This Pull Request bring back Kamitani reconstruction example.

It adds the function to fetch the dataset, a bit of code from visvis to produce animated gifs and an exemple that perform a reconstruction and output it in a gif and a video.
",start issue,Kamitani example
2,issue_closed,101,nilearn,nilearn,agramfort,2013-09-19 20:55:17,,closed issue,Kamitani example
3,pull_request_title,101,nilearn,nilearn,AlexandreAbraham,2013-09-04 07:43:25,"This Pull Request bring back Kamitani reconstruction example.

It adds the function to fetch the dataset, a bit of code from visvis to produce animated gifs and an exemple that perform a reconstruction and output it in a gif and a video.
",213d2cbc389dfd64a7b0e9820e465c270ea20abe,Kamitani example
4,issue_comment,101,nilearn,nilearn,agramfort,2013-09-04 14:33:18,"the movie error remains.

/Users/alex/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/matplotlib/backends/backend_agg.pyc
in print_raw(self, filename_or_obj, _args, *_kwargs)
    495             close = False
    496         try:
--> 497             renderer._renderer.write_rgba(filename_or_obj)
    498         finally:
    499             if close:

RuntimeError: Error writing to file

On Wed, Sep 4, 2013 at 4:11 PM, Alexandre Abraham
notifications@github.comwrote:

> @agramfort https://github.com/agramfort I have removed the gif
> generation. Could you try to rerun the script ?
> 
> —
> Reply to this email directly or view it on GitHubhttps://github.com/nilearn/nilearn/pull/101#issuecomment-23791948
> .
",,
5,issue_comment,101,nilearn,nilearn,agramfort,2013-09-04 15:05:57,"Fails on my box too :-/

Le 4 sept. 2013 à 16:59, Gael Varoquaux notifications@github.com a écrit :

> > Seems like animation saving relies on a system call to ffmpeg and is not very
> > reliable / cross platform...
> 
> OK, back to gif, then.
> —
> Reply to this email directly or view it on GitHub.
",,
6,issue_comment,101,nilearn,nilearn,agramfort,2013-09-15 19:05:26,"wdyt of naming miyawaki2008 the dataset instead of kamitani? it's more natural to cite the first author.
so fetch_miyawaki2008 etc.

@GaelVaroquaux any thoughts?
",,
7,issue_comment,101,nilearn,nilearn,agramfort,2013-09-16 17:10:52,"examples runs fine now

but I get these warnings

plot_miyawaki_reconstruction.py:109: DeprecationWarning: axis != 0 for ndim == 1; this will raise an error in future versions of numpy
  for y, t, l, b in zip(y_train, yt_tall, yt_large, yt_big)]
plot_miyawaki_reconstruction.py:109: DeprecationWarning: axis != 0 for ndim == 1; this will raise an error in future versions of numpy
  for y, t, l, b in zip(y_train, yt_tall, yt_large, yt_big)]
plot_miyawaki_reconstruction.py:109: DeprecationWarning: axis != 0 for ndim == 1; this will raise an error in future versions of numpy
  for y, t, l, b in zip(y_train, yt_tall, yt_large, yt_big)]
plot_miyawaki_reconstruction.py:109: DeprecationWarning: axis != 0 for ndim == 1; this will raise an error in future versions of numpy
",,
8,issue_comment,101,nilearn,nilearn,agramfort,2013-09-19 20:47:24,"I am on it. I'll merge in a bit after a tiny cosmit.
",,
9,issue_comment,101,nilearn,nilearn,agramfort,2013-09-19 20:49:47,"can you grant me commit rights ??? :(
",,
10,issue_comment,101,nilearn,nilearn,agramfort,2013-09-19 20:50:07,"I cannot push :(
",,
11,issue_comment,101,nilearn,nilearn,agramfort,2013-09-19 20:54:49,"> Tu as été sage?

oui papa
",,
12,issue_comment,101,nilearn,nilearn,agramfort,2013-09-19 20:55:17,"merged by rebase !
",,
13,issue_comment,101,nilearn,nilearn,GaelVaroquaux,2013-09-04 14:59:55,"> Seems like animation saving relies on a system call to ffmpeg and is not very
> reliable / cross platform...

OK, back to gif, then.
",,
14,issue_comment,101,nilearn,nilearn,GaelVaroquaux,2013-09-04 15:06:44,"> Fails on my box too :-/

But we can fix this if you send us an actual traceback.
",,
15,issue_comment,101,nilearn,nilearn,GaelVaroquaux,2013-09-04 15:13:24,"> Gif generation is broken on MacOS too. This is a very old bug that won't be
> fixed in a near future I think...
> matplotlib/matplotlib#531

Then forget the movie, and just do 10 still images.
",,
16,issue_comment,101,nilearn,nilearn,GaelVaroquaux,2013-09-05 13:02:19,"> Maybe I could do 10 images and save the movie in a try ... except ?

No, let's just avoid spending too much time and code on the movie. I
don't think that its value is that high.
",,
17,issue_comment,101,nilearn,nilearn,GaelVaroquaux,2013-09-15 21:03:01,"Agreed.

> wdyt of naming miyawaki2008 the dataset instead of kamitani? it's more
> natural to cite the first author. so fetch_miyawaki2008 etc.
",,
18,issue_comment,101,nilearn,nilearn,GaelVaroquaux,2013-09-19 20:43:10,"@eickenberg : could you have a look at this PR? You know the science better than most of us. In particular, could you give feedback on the example?
",,
19,issue_comment,101,nilearn,nilearn,GaelVaroquaux,2013-09-19 20:53:18,"> can you grant me commit rights ??? :(

Tu as été sage?
",,
20,issue_comment,101,nilearn,nilearn,AlexandreAbraham,2013-09-04 14:11:33,"@agramfort I have removed the gif generation. Could you try to rerun the script ?
",,
21,issue_comment,101,nilearn,nilearn,AlexandreAbraham,2013-09-04 14:47:13,"Seems like animation saving relies on a system call to ffmpeg and is not very reliable / cross platform...
",,
22,issue_comment,101,nilearn,nilearn,AlexandreAbraham,2013-09-04 15:08:22,"> OK, back to gif, then.

Gif generation is broken on MacOS too. This is a very old bug that won't be fixed in a near future I think...
https://github.com/matplotlib/matplotlib/issues/531
",,
23,issue_comment,101,nilearn,nilearn,AlexandreAbraham,2013-09-05 11:31:48,"Maybe I could do 10 images and save the movie in a try ... except ?
",,
24,issue_comment,101,nilearn,nilearn,bthirion,2013-09-14 20:53:32,"This is good. Thanks for taking time on this.
",,
25,issue_comment,101,nilearn,nilearn,bthirion,2013-09-15 21:05:37,"+1
",,
26,issue_comment,101,nilearn,nilearn,AlexandreAbraham,2013-09-15 21:23:00,"Done in the code but I'll have to change the file uploaded on nitrc.
",,
27,issue_comment,101,nilearn,nilearn,AlexandreAbraham,2013-09-19 16:17:56,"I have completely replaced ""kamitani"" by ""miyawaki2008"". I have also changed the file on the nitrc server.
Warning: I have rebased the PR on master recently.
",,
28,issue_comment,101,nilearn,nilearn,AlexandreAbraham,2013-09-19 16:31:33,"I have added a progress output in the example script since it takes nearly 4 minutes to run it on my box.

Is everybody OK for merging ?
",,
29,pull_request_commit_comment,101,nilearn,nilearn,GaelVaroquaux,2013-09-04 08:39:24,"Tell us more in the docstring.
",213d2cbc389dfd64a7b0e9820e465c270ea20abe,"(None, '', u'plot_kamitani_reconstruction.py')"
30,pull_request_commit_comment,101,nilearn,nilearn,GaelVaroquaux,2013-09-04 08:41:28,"We don't need both an mp4 and a animated gif. If the mp4 works reliably, let's drop the gif. This will avoid to have to pull in some visvis code.
",213d2cbc389dfd64a7b0e9820e465c270ea20abe,"(None, '', u'plot_kamitani_reconstruction.py')"
31,pull_request_commit_comment,101,nilearn,nilearn,GaelVaroquaux,2013-09-04 08:43:01,"The following needs more comments. It is somewhat convoluted.
",213d2cbc389dfd64a7b0e9820e465c270ea20abe,"(None, '', u'plot_kamitani_reconstruction.py')"
32,pull_request_commit_comment,101,nilearn,nilearn,AlexandreAbraham,2013-09-04 08:43:19,"Video works reliably but requires matplotlib 1.0.
",213d2cbc389dfd64a7b0e9820e465c270ea20abe,"(None, '', u'plot_kamitani_reconstruction.py')"
33,pull_request_commit_comment,101,nilearn,nilearn,GaelVaroquaux,2013-09-04 08:43:35,"I think that you have too many options. Make choices: do multi_scale or do not. Try you must not.
",213d2cbc389dfd64a7b0e9820e465c270ea20abe,"(None, '', u'plot_kamitani_reconstruction.py')"
34,pull_request_commit_comment,101,nilearn,nilearn,GaelVaroquaux,2013-09-04 08:44:14,"Same thing here: just remove the rest period. No need for an if.
",213d2cbc389dfd64a7b0e9820e465c270ea20abe,"(None, '', u'plot_kamitani_reconstruction.py')"
35,pull_request_commit_comment,101,nilearn,nilearn,GaelVaroquaux,2013-09-04 08:46:27,"> Video works reliably but requires matplotlib 1.0.

It was released in January 2011. Let's move on and use it (yes, I am aware
that this won't work on Ubuntu 10.04 LTS)
",213d2cbc389dfd64a7b0e9820e465c270ea20abe,"(None, '', u'plot_kamitani_reconstruction.py')"
36,pull_request_commit_comment,101,nilearn,nilearn,agramfort,2013-09-04 11:26:53,"just tried the script:

Downloading data from
https://www.nitrc.org/frs/download.php/5853/kamitani.tgz?i_agree=1&download_now=1...
Downloaded 62119936 of 161003254 bytes (38.58%, 15.8min remaining)
...done. (597 seconds, 9 min)
extracting data from
/Users/alex/work/src/nilearn/nilearn_data/kamitani/kamitani.tgz...
Error uncompressing file: CRC check failed 0x4928241c != 0x2d831715L
An error occured, fetching aborted. Please see the full log above.

can anybody reproduce?
",213d2cbc389dfd64a7b0e9820e465c270ea20abe,"(None, '', u'plot_kamitani_reconstruction.py')"
37,pull_request_commit_comment,101,nilearn,nilearn,agramfort,2013-09-04 11:46:09,"if I rerun the script it works... don't ask why.
But I get an error when saving the animation.

In [11]: matplotlib.**version**
Out[11]: '1.3.0'

I get:

/Users/alex/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/matplotlib/backends/backend_agg.pyc
in print_raw(self, filename_or_obj, _args, *_kwargs)
    495             close = False
    496         try:
--> 497             renderer._renderer.write_rgba(filename_or_obj)
    498         finally:
    499             if close:

RuntimeError: Error writing to file
",213d2cbc389dfd64a7b0e9820e465c270ea20abe,"(None, '', u'plot_kamitani_reconstruction.py')"
38,pull_request_commit_comment,101,nilearn,nilearn,agramfort,2013-09-04 11:47:24,"if fails also with the gif:

/Users/alex/work/src/nilearn/plot_kamitani_reconstruction.py in fig2data(fig)
    326     # Get the RGB buffer from the figure
    327     w, h = fig.canvas.get_width_height()
--> 328     buf = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8)
    329     buf.shape = (h, w, 3)
    330     return buf

AttributeError: 'FigureCanvasMac' object has no attribute 'tostring_rgb'

On Wed, Sep 4, 2013 at 1:45 PM, Alexandre Gramfort
alexandre.gramfort@m4x.org wrote:

> if I rerun the script it works... don't ask why.
> But I get an error when saving the animation.
> 
> In [11]: matplotlib.**version**
> Out[11]: '1.3.0'
> 
> I get:
> 
> /Users/alex/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/matplotlib/backends/backend_agg.pyc
> in print_raw(self, filename_or_obj, _args, *_kwargs)
>     495             close = False
>     496         try:
> --> 497             renderer._renderer.write_rgba(filename_or_obj)
>     498         finally:
>     499             if close:
> 
> RuntimeError: Error writing to file
",213d2cbc389dfd64a7b0e9820e465c270ea20abe,"(None, '', u'plot_kamitani_reconstruction.py')"
39,pull_request_commit_comment,101,nilearn,nilearn,bthirion,2013-09-14 20:49:57,"Could you explain somewhere why you use OMP ? For the sake of fficiency or because it works well ?
",213d2cbc389dfd64a7b0e9820e465c270ea20abe,"(None, '', u'plot_kamitani_reconstruction.py')"
40,pull_request_commit_comment,101,nilearn,nilearn,bthirion,2013-09-14 20:52:37,"Sorry, but could you be a bit more precise than just ""Percentage"" ? May be ""Accuracy (percent)""
",213d2cbc389dfd64a7b0e9820e465c270ea20abe,"(None, '', u'plot_kamitani_reconstruction.py')"
41,pull_request_commit_comment,101,nilearn,nilearn,AlexandreAbraham,2013-09-14 21:44:17,"Like other examples, I will add a page in the manual to explain. In this case (reconstruction / multiscale strategy), OMP is slightly faster and gives better results than L1 penalized Logistic Regression (these are the two methods with best results among all I tried).
",213d2cbc389dfd64a7b0e9820e465c270ea20abe,"(None, '', u'plot_kamitani_reconstruction.py')"
42,pull_request_commit_comment,101,nilearn,nilearn,agramfort,2013-09-15 18:56:53,"missing ref
",213d2cbc389dfd64a7b0e9820e465c270ea20abe,"(None, '', u'nilearn/datasets.py')"
43,pull_request_commit_comment,101,nilearn,nilearn,agramfort,2013-09-15 18:57:16,"or remove section if empty no?
",213d2cbc389dfd64a7b0e9820e465c270ea20abe,"(None, '', u'nilearn/datasets.py')"
44,pull_request_commit_comment,101,nilearn,nilearn,agramfort,2013-09-15 18:58:51,"Reconstruction of visual stimuli (Miyawaki et al. 2008)

Kamitani paper is our jargon :)
",213d2cbc389dfd64a7b0e9820e465c270ea20abe,"(None, '', u'plot_kamitani_reconstruction.py')"
45,pull_request_commit_comment,101,nilearn,nilearn,agramfort,2013-09-15 19:01:46,"y_pred = [clf.predict(X_test) for clf in clfs]

is shorter.
",213d2cbc389dfd64a7b0e9820e465c270ea20abe,"(None, '', u'plot_kamitani_reconstruction.py')"
46,pull_request_commit_comment,101,nilearn,nilearn,agramfort,2013-09-15 19:02:40,"why the _ prefix? it is weird to have a private function in an example.
",213d2cbc389dfd64a7b0e9820e465c270ea20abe,"(None, '', u'plot_kamitani_reconstruction.py')"
47,pull_request_commit_comment,101,nilearn,nilearn,agramfort,2013-09-15 19:03:23,"no video anymore.
",213d2cbc389dfd64a7b0e9820e465c270ea20abe,"(None, '', u'plot_kamitani_reconstruction.py')"
48,pull_request_commit_comment,101,nilearn,nilearn,AlexandreAbraham,2013-09-15 19:36:17,"The reference is below in Notes: paper to cite. Maybe we should put it here.
",213d2cbc389dfd64a7b0e9820e465c270ea20abe,"(None, '', u'nilearn/datasets.py')"
49,pull_request_commit_comment,101,nilearn,nilearn,agramfort,2013-09-15 19:37:16,"I've seen but it's weird to have an empty section
",213d2cbc389dfd64a7b0e9820e465c270ea20abe,"(None, '', u'nilearn/datasets.py')"
50,pull_request_commit_comment,101,nilearn,nilearn,AlexandreAbraham,2013-09-15 19:39:21,"We prefer to put explicit loops for people who are not familiar with list comprehension.
",213d2cbc389dfd64a7b0e9820e465c270ea20abe,"(None, '', u'plot_kamitani_reconstruction.py')"
51,pull_request_commit_comment,101,nilearn,nilearn,AlexandreAbraham,2013-09-15 19:41:39,"Fixed.
",213d2cbc389dfd64a7b0e9820e465c270ea20abe,"(None, '', u'plot_kamitani_reconstruction.py')"
52,pull_request_commit_comment,101,nilearn,nilearn,AlexandreAbraham,2013-09-15 19:41:47,"Fixed.
",213d2cbc389dfd64a7b0e9820e465c270ea20abe,"(None, '', u'plot_kamitani_reconstruction.py')"
53,pull_request_commit_comment,101,nilearn,nilearn,agramfort,2013-09-15 19:47:24,"oh well.... it's a detail anyway.
",213d2cbc389dfd64a7b0e9820e465c270ea20abe,"(None, '', u'plot_kamitani_reconstruction.py')"
54,pull_request_commit_comment,101,nilearn,nilearn,AlexandreAbraham,2013-09-16 11:35:57,"Fixed.
",213d2cbc389dfd64a7b0e9820e465c270ea20abe,"(None, '', u'nilearn/datasets.py')"
55,pull_request_commit_comment,101,nilearn,nilearn,agramfort,2013-09-16 17:07:03,"I still see the empty section
",213d2cbc389dfd64a7b0e9820e465c270ea20abe,"(None, '', u'nilearn/datasets.py')"
56,pull_request_commit_comment,101,nilearn,nilearn,agramfort,2013-09-16 17:07:26,"I'd remove the

## Notes
",213d2cbc389dfd64a7b0e9820e465c270ea20abe,"(None, '', u'nilearn/datasets.py')"
57,pull_request_commit_comment,101,nilearn,nilearn,agramfort,2013-09-16 17:08:19,"the PR is not up to date apparently.
",213d2cbc389dfd64a7b0e9820e465c270ea20abe,"(None, '', u'nilearn/datasets.py')"
58,pull_request_commit_comment,101,nilearn,nilearn,ogrisel,2013-09-18 09:50:33,"s/kamitani/Miyawaki/g
",213d2cbc389dfd64a7b0e9820e465c270ea20abe,"(None, '', u'nilearn/datasets.py')"
59,pull_request_commit_comment,101,nilearn,nilearn,ogrisel,2013-09-18 09:52:44,"It would be interesting to state the total size of the data files that will be download by calling this function.
",213d2cbc389dfd64a7b0e9820e465c270ea20abe,"(None, '', u'nilearn/datasets.py')"
60,pull_request_commit_comment,101,nilearn,nilearn,AlexandreAbraham,2013-09-19 16:16:43,"Fixed. Thanks for the review !
",213d2cbc389dfd64a7b0e9820e465c270ea20abe,"(None, '', u'nilearn/datasets.py')"
61,pull_request_commit,101,nilearn,nilearn,AlexandreAbraham,2013-09-03 15:41:14,Add Kamitani dataset fetching,8ae0f91e5a1274e046a294fb1f3b1ba78b86575b,
62,pull_request_commit,101,nilearn,nilearn,AlexandreAbraham,2013-09-03 15:42:18,Add a module to generate animated gif for Kamitani example.,540368cac22b9b35fc90b7bcfb7ae49f507d69fc,
63,pull_request_commit,101,nilearn,nilearn,AlexandreAbraham,2013-09-03 15:43:01,Add Kamitani reconstruction example,e8836672946921c0a5ddafef04c01b9429337711,
64,pull_request_commit,101,nilearn,nilearn,AlexandreAbraham,2013-09-04 12:25:26,Add Miyawaki paper to Kamitani fetching function,94a6ed746eb7217e9525c7afa8362f7ac6505fe4,
65,pull_request_commit,101,nilearn,nilearn,AlexandreAbraham,2013-09-04 12:27:42,"Enhance doc, remove options",dc05991f0f0aec1b32734db2bafc4764205c2e16,
66,pull_request_commit,101,nilearn,nilearn,AlexandreAbraham,2013-09-04 14:08:52, Fix remarks,5680a46d4e70946c36438127d078f6b04f39c632,
67,pull_request_commit,101,nilearn,nilearn,AlexandreAbraham,2013-09-04 14:09:27,Remove gif generation,683f97dc24968d1ac5c1b4a4e5a3226267ed4465,
68,pull_request_commit,101,nilearn,nilearn,AlexandreAbraham,2013-09-10 13:23:55,Output images instead of video,ff48a6c6c9c840621ebf85a4baf96f48c098da76,
69,pull_request_commit,101,nilearn,nilearn,AlexandreAbraham,2013-09-10 14:14:15,Remove external dir from setup,f238fa00207964627ed2165d1b4971e87e1075d2,
70,pull_request_commit,101,nilearn,nilearn,AlexandreAbraham,2013-09-14 21:00:41,Fix string,d4fbf2b7656304ee440e688d8c7ca470067ac8c9,
71,pull_request_commit,101,nilearn,nilearn,AlexandreAbraham,2013-09-14 21:35:51,Enhance output,50489e28c079d9c17cad0b454d1a78ba7452f662,
72,pull_request_commit,101,nilearn,nilearn,AlexandreAbraham,2013-09-15 19:40:40,Little fixes,6dc419928e03b68a171542e9f2f1187b48e457ae,
73,pull_request_commit,101,nilearn,nilearn,AlexandreAbraham,2013-09-15 21:21:03,Replace kamitani by miyawaki2008,c1a8950bc3f1a47fdc5624ed665cbef4c2dfd9f2,
74,pull_request_commit,101,nilearn,nilearn,AlexandreAbraham,2013-09-16 20:38:55,Replace Kamitani by Miyawaki,d2eefc760261a37f16b74af3e359120559da679d,
75,pull_request_commit,101,nilearn,nilearn,AlexandreAbraham,2013-09-19 13:51:19,s/kamitani/Miyawaki/,8a4ea7d22241efb22b97bf85c87a113fa082d727,
76,pull_request_commit,101,nilearn,nilearn,AlexandreAbraham,2013-09-19 16:14:01,Use newly uploaded file for the dataset,486048a9ceeb0d494ede0d6cb2238ee47fe50305,
77,pull_request_commit,101,nilearn,nilearn,AlexandreAbraham,2013-09-19 16:16:08,Add size of Miyawaki dataset,689e8806889a96fb66c99dd04b78373dedea029a,
78,pull_request_commit,101,nilearn,nilearn,AlexandreAbraham,2013-09-19 16:29:12,Better output of Miyawaki example script,213d2cbc389dfd64a7b0e9820e465c270ea20abe,
0,rectype,issueid,project_owner,project_name,actor,time,text,action,title
1,issue_title,102,nilearn,nilearn,rphlypo,2013-09-04 14:50:03,"The link to ""source code (github)"" on http://nilearn.github.io/index.html seems broken
",start issue,Broken link on http://nilearn.github.io/index.html
2,issue_closed,102,nilearn,nilearn,AlexandreAbraham,2013-09-04 15:03:16,,closed issue,Broken link on http://nilearn.github.io/index.html
3,issue_comment,102,nilearn,nilearn,AlexandreAbraham,2013-09-04 15:03:16,"Fixed.
",,
0,rectype,issueid,project_owner,project_name,actor,time,text,action,title
1,issue_title,103,nilearn,nilearn,rphlypo,2013-09-04 14:54:24,"When downloading a dataset this is by default in the current directory. However, one does not necessarily group all of its code in the ""data"" directory. It would be nice to 

1) either, warn the end user that the data may be placed wherever as long as a environment variable NILEARN_DATA is created containing a pointer to that directory;

2) or, upon absence of the environment variable, create it from within the procedure (warning could still be issued if needed)
",start issue,Downloading data with datasets.fetch_XX
2,issue_closed,103,nilearn,nilearn,AlexandreAbraham,2014-10-31 08:33:08,,closed issue,Downloading data with datasets.fetch_XX
3,issue_comment,103,nilearn,nilearn,AlexandreAbraham,2014-10-31 08:33:06,"This issue is now treated in #244.
",,
4,issue_comment,103,nilearn,nilearn,AlexandreAbraham,2014-03-31 15:57:22,"I am totally against option 2: a software must not mess the user configuration files.

Warning the user seems like a good idea to me. Another option would be to store data in a fixed path like `~/.nilearn`. I think that this is the behavior of most softwares. The problem is that it may not be obvious for people who are not into computer science, if they want to go and see directly the content of the dataset. The other problem is that it a bit user-friendly on Linux, but we would end up with a folder in the AppData folder on windows and I think that most of users does not even know that it exists.

@GaelVaroquaux Any thoughts on this one ? Sorry to highlight you everywhere but I'm cleaning nilearn issues list.
",,
0,rectype,issueid,project_owner,project_name,actor,time,text,action,title
1,issue_title,100,nilearn,nilearn,pgervais,2013-08-29 11:59:45,"This is an implementation of the algorithm described in 

_Jean Honorio and Dimitris Samaras ""Simultaneous and Group-Sparse Multi-Task Learning of Gaussian Graphical Models"", arXiv:1207.4255 (17 July 2012), http://arxiv.org/abs/1207.4255._

Given several sets of input signals, it computes several sparse precision matrices at once, using a common sparsity pattern.

The implementation itself is already fairly stable and optimized. It remains mainly some technical issues (like API, argument names, etc.). Namely:
- [x] Settle on names for functions and classes, the current ones may not be the best (group_sparse_covariance GroupSparseCovariance and GroupSparseCovarianceCV)
- [x] Clean up handling of stopping criteria (esp. the _group_sparse_covariance_costs function)
- [x] Separate in GroupSparseCovarianceCV the parameters for selection of alpha and parameters for final fit.
- [x] Automatically normalize input signals.
- [x] Clean up user messages, use the logging system of PR #84 (or similar). 
- [x] Write some documentation on the inner working of the CV version, namely the modified stopping criterion to stop optimization.
- [x] Rename the internal variable `Winv` into `W_inv`
- [x] Rename the regularization parameter `rho` to `alpha`, to match scikit-learn's convention. This implies renaming an internal variable already called `alpha`
- [x] add support for caching in GroupSparseCovariance|CV
",start issue,"[ENH] Group-sparse precision estimation, by Honorio & Samaras."
2,issue_closed,100,nilearn,nilearn,GaelVaroquaux,2013-09-18 16:24:24,,closed issue,"[ENH] Group-sparse precision estimation, by Honorio & Samaras."
3,pull_request_title,100,nilearn,nilearn,pgervais,2013-08-29 11:59:45,"This is an implementation of the algorithm described in 

_Jean Honorio and Dimitris Samaras ""Simultaneous and Group-Sparse Multi-Task Learning of Gaussian Graphical Models"", arXiv:1207.4255 (17 July 2012), http://arxiv.org/abs/1207.4255._

Given several sets of input signals, it computes several sparse precision matrices at once, using a common sparsity pattern.

The implementation itself is already fairly stable and optimized. It remains mainly some technical issues (like API, argument names, etc.). Namely:
- [x] Settle on names for functions and classes, the current ones may not be the best (group_sparse_covariance GroupSparseCovariance and GroupSparseCovarianceCV)
- [x] Clean up handling of stopping criteria (esp. the _group_sparse_covariance_costs function)
- [x] Separate in GroupSparseCovarianceCV the parameters for selection of alpha and parameters for final fit.
- [x] Automatically normalize input signals.
- [x] Clean up user messages, use the logging system of PR #84 (or similar). 
- [x] Write some documentation on the inner working of the CV version, namely the modified stopping criterion to stop optimization.
- [x] Rename the internal variable `Winv` into `W_inv`
- [x] Rename the regularization parameter `rho` to `alpha`, to match scikit-learn's convention. This implies renaming an internal variable already called `alpha`
- [x] add support for caching in GroupSparseCovariance|CV
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"[ENH] Group-sparse precision estimation, by Honorio & Samaras."
4,pull_request_merged,100,nilearn,nilearn,GaelVaroquaux,2013-09-18 16:24:24,"[ENH] Group-sparse precision estimation, by Honorio & Samaras.",2dce8db3fc8e299af6c09272c98a3d9ba9d5246a,Pull request merge from pgervais/nilearn:honorio_samaras to nilearn/nilearn:master
5,issue_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-29 12:22:12,"Travis failed... with what looks as a somewhat trivial bug.
",,
6,issue_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-29 12:43:03,">    I know that looking at the example is the simplest thing to do. And I also
>    know that there is many things to do, including those that you just
>    pointed out. What I really need is feedback on the core of the
>    algorithm...

I need to be able to run it to inspect it.
",,
7,issue_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-30 08:23:48,"I just noticed that the group_sparse_covariance tests are very long running. We should work on making them faster.
",,
8,issue_comment,100,nilearn,nilearn,GaelVaroquaux,2013-09-05 16:37:24,"> Wait. I already have the answer: compare the two algorithms.

Yup
",,
9,issue_comment,100,nilearn,nilearn,pgervais,2013-08-29 12:23:52,"I didn't check the tests before creating the PR. I'll fix that soon.
",,
10,issue_comment,100,nilearn,nilearn,pgervais,2013-08-29 12:39:53,"I know that looking at the example is the simplest thing to do. And I also know that there is many things to do, including those that you just pointed out. What I really need is feedback on the core of the algorithm...
",,
11,issue_comment,100,nilearn,nilearn,bthirion,2013-09-03 21:34:29,"Tnx for the nice work, and sorry for bothering you with details. This PR should obviously get in. 
",,
12,issue_comment,100,nilearn,nilearn,pgervais,2013-09-05 15:46:32,"I'm now starting to clean up the examples that show off GroupSparseCovarianceCV. There are two files that do almost the same thing: `plot_adhd_covariance.py` and `plot_adhd_covariance2.py`. The first loads data for one subject, and compute a CV'd graph lasso. The second loads data for several subjects and compute a CV'd group-sparse covariance. There are in practice only one thing that differs between them: the optimization algorithm. The code is mostly copy-pasted.

I think keeping only the group-sparse one is enough. What do you think?
",,
13,issue_comment,100,nilearn,nilearn,pgervais,2013-09-05 15:47:46,"Wait. I already have the answer: compare the two algorithms. 
",,
14,issue_comment,100,nilearn,nilearn,pgervais,2013-09-11 13:12:54,"In the last commits, I added two pages of documentation. One is about functional connectivity analysis with nilearn (in user's guide, under ""unsupervised learning""), the other is a technical description of the implementation of the group-sparse covariance algorithm. The latter is accessible via a link at the very bottom of the former. This link is rather hard to find, it has been done on purpose: the technical page is for developers or machine-learning guys.
",,
15,issue_comment,100,nilearn,nilearn,bthirion,2013-09-11 21:31:55,"Besides a couple of typos, everything looks file. Thanks for the documentation.
",,
16,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-29 12:32:55,"This file need a better name and a better title.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'plot_adhd_covariance2.py')"
17,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-29 12:34:45,"Why these commented lines?
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'plot_adhd_covariance2.py')"
18,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-29 12:35:13,"We don't do 'if **name**'... in examples, they have to be as simple as possible.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'plot_adhd_covariance2.py')"
19,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-29 12:36:53,"I don't think that this should be in a function, but should be in the top-level.

I also think that we should be demoing the object, and not the path function.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'plot_adhd_covariance2.py')"
20,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-29 12:38:15,"The io module has been move to 'input_data'. You probably have some .pyc files that remain on your hard drive.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'plot_adhd_covariance2.py')"
21,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-29 12:40:44,"The fact that we need this function is telling me that we have a broken API. It is the role of the objects in input_data to do this, and we _shouldn't_ have to define such functions.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'plot_adhd_covariance2.py')"
22,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-29 12:45:54,"I think that you missing a whitespace before the "":"", elsewhere the docstring won't be rendered well by the numpy docstring scrapper (that's true for all docstrings).
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/tests/test_group_sparse_covariance.py')"
23,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-29 12:46:25,"I'd rather use np.empty here.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/tests/test_group_sparse_covariance.py')"
24,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-29 12:47:32,"I think that you mean 'n_samples, n_features'. Let's stick to the same vocabulary as with the scikit-learn.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/tests/test_group_sparse_covariance.py')"
25,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-29 12:48:41,"The last argument should be called 'random_state' as in the scikit-learn, and you should use check_random_state to be as flexible as the scikit-learn is with regards to the input argument.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/tests/test_group_sparse_covariance.py')"
26,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-29 12:49:06,"Capital ""G"" for ""Gaussian"".
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/tests/test_group_sparse_covariance.py')"
27,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-29 12:51:44,"I think that this function should be in the public API to be used in an example.

Also, I'd like the notion of 'task' to disappear from the codebase: it is machine learning jargon that will not talk to neuroimagers. We could for instance call this function ""generate_group_sparse_gaussian_graphs"", and rename ""n_tasks"" to ""n_subjects"".
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/tests/test_group_sparse_covariance.py')"
28,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-29 12:55:02,"Once again, I'd rather use np.empty here.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/signal.py')"
29,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-29 12:56:25,"It seems to me that a lot of this could be done using sklearn.utils.gen_even_slices.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/signal.py')"
30,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-29 12:58:59,"Here also, sklearn.utils.gen_even_slices might be useful.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/signal.py')"
31,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-29 13:00:16,"I believe that it should be very fast compared to the rest.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
32,pull_request_commit_comment,100,nilearn,nilearn,pgervais,2013-08-29 13:00:26,"True, I realized that recently. There's more than this file to fix ...
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/tests/test_group_sparse_covariance.py')"
33,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-29 13:00:54,"I am thinking that this should be a callable.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(791, '', u'nilearn/group_sparse_covariance.py')"
34,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-29 13:01:23,"I think that I'd like the world 'callable' in the first line of the docstring.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
35,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-29 13:05:30,"You should make it a dictionary, I believe, as it will make forward evolution easier.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
36,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-29 13:06:27,"I believe that this is 'callable or None'. Note also the missing white-space before the semi-colon.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
37,pull_request_commit_comment,100,nilearn,nilearn,pgervais,2013-08-29 13:06:30,"This function is not called by the script. It is a remain of some experiment.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'plot_adhd_covariance2.py')"
38,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-29 13:09:14,"By number of signals, I think that you mean ""n_features"" in machine learning speech. You should have both (say one in parenthesis): I understand that for a layman ""number of signals"" is more intuitive, but ""n_features"" is more precise for a scikit-learn user.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
39,pull_request_commit_comment,100,nilearn,nilearn,pgervais,2013-08-29 13:11:03,"That's possible, but is not the point addressed by this PR. Please open an issue.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'plot_adhd_covariance2.py')"
40,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-29 13:11:31,"I feel that this should be a private function.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
41,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-29 13:11:52,"This should also be private, I believe.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
42,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-29 13:12:34,"""display"" should probably be renamed ""verbose"", to stick with scikit-learn conventions.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
43,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-29 13:14:21,"Do you need to specify n_tasks and n_var? I believe that you can infer them from emp_covs, which would make the signature of this function lighter.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
44,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-29 13:16:06,"I think that writing ""Honorio & Samaras"" would be easier to read for the non-expert (I do realize that this is a comment, by still...)
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
45,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-29 13:17:46,"The returns is false: there are 3 return arguments.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
46,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-29 13:18:32,"longer names would make it much easier to read for people.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
47,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-29 13:18:57,"You should be using scipy.linalg, not np.linalg.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
48,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-29 13:21:29,"Why do you have to copy omega?
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
49,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-29 13:22:59,"It would probably help if you would give the shape of the arrays (and is the above an array)
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
50,pull_request_commit_comment,100,nilearn,nilearn,pgervais,2013-08-29 13:30:11,"I didn't know about gen_even_slices when I wrote this function. I'll fix it.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/signal.py')"
51,pull_request_commit_comment,100,nilearn,nilearn,pgervais,2013-08-29 13:38:13,"What about ""number of features""? Beside, who are we targetting here? The neuroscientist, or the machine learning user? It the former case, the ""task"" input argument should be renamed ""subjects"". 
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
52,pull_request_commit_comment,100,nilearn,nilearn,pgervais,2013-08-29 13:51:18,"To keep track of it along iteration. This has been superseded by the probe system. 
BTW this function is never called in the current code, because the stopping criterion relies on something else now. 
However, before dropping this function altogether, it may be interesting to know if the duality gap computation can be useful to someone.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
53,pull_request_commit_comment,100,nilearn,nilearn,pgervais,2013-08-29 13:57:00,"The name of the function is also highly annoying. I keep trying to write things like `rho_max = rho_max(emp_covs, n_samples)`. I think `get_rho_max` or `compute_rho_max` would be better. Is there a scikit-learn convention on this matter?
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
54,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-29 14:14:12,"On Thu, Aug 29, 2013 at 06:38:14AM -0700, Philippe Gervais wrote:

>    What about ""number of features""? Beside, who are we targetting here? The
>    neuroscientist, or the machine learning user? It the former case, the
>    ""task"" input argument should be renamed ""subjects"".

A bit of both. However, feature is very standard, very tasks is less. It
might be useful to put in some places signals in parenthesis, just to
make things easier for people.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
55,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-29 14:18:58,">    To keep track of it along iteration. This has been superseded by the probe
>    system.

OK, but in the non CV estimator, isn't it used? I would expect that the
dual gap would be a good stopping criterion in this situation. I think
that we had a conversation on that. No use reminding me what the
conclusion were, just go ahead with what you think is right and drop it
if you feel that there is no use for it.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
56,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-29 14:19:54,">    The name of the function is also highly annoying. I keep trying to write
>    things like rho_max = rho_max(emp_covs, n_samples). I think get_rho_max or
>    compute_rho_max would be better. Is there a scikit-learn convention on
>    this matter?

No, but I think that compute_foo is a good name.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
57,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-30 10:08:15,"n_var should be n_features
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
58,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-30 10:11:22,"Please tell us in one line what this does (alpha_max may not be clear to somebody not knowing the problem well).
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
59,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-30 10:14:26,"true_sub = np.empty_like(sub)
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
60,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-30 10:21:32,"Honestly, in empirical_covariances, I would give up on the debug features. By definition, the formula gives us SPD matrices. I know that with numerical errors they _might_ not be, but how often have you seen this happen?
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
61,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-30 10:34:01,"n_var -> n_features

Also, the shape description should be on line above.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
62,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-30 10:38:19,"I think that you are returning too many things. n_subjects and n_var (which should be named n_features) can be trivially inferred from emp_covs. As a side note, I don't believe that you are using those return arguments in your code.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
63,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-30 10:40:17,"I would use 'log_likelihood' or 'log_lik' in the name, rather than score, which is not very specific. Same thing about the 'score' word in the first line.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
64,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-30 10:41:00,"I think that we need better names, for instance 'log_lik'.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
65,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-30 10:42:00,"I believe that this is not the loss, but the objective function, which is the sum of a loss and a regularization.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
66,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-30 11:40:26,"You should inherit from sklearn.base.BaseEstimator
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
67,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-30 11:43:13,"self.cv_scores and self.cv_alphas should have a trailing underscore, as they are derived from data.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
68,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-30 11:47:15,"I don't think that random_state is documented. Anyhow, it should be a more versatile input type, and accept also anything that can be a seed. For this, you need to rely on check_random_state from scikit-learn.

Also, your current implementation has a mutable in its function definition. I don't think that it works as you expect: if you call it twice in the same Python function, it won't give the same result.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/tests/test_group_sparse_covariance.py')"
69,pull_request_commit_comment,100,nilearn,nilearn,pgervais,2013-08-30 11:47:26,"Granted. I wanted to avoid a call to .shape in an loop. This proved useless later on.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
70,pull_request_commit_comment,100,nilearn,nilearn,pgervais,2013-08-30 11:50:14,"This function both returns the log-likelihood, and the quantity optimized by the algorithm, which is the opposite of the log-likelihood, penalized. A good common word for these two unrelated quantities was ""score"". In the case of the log-likelihood, it matches scikit-learn's convention.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
71,pull_request_commit_comment,100,nilearn,nilearn,pgervais,2013-08-30 11:50:53,"This has been corrected.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
72,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-08-30 11:56:17,">    This function both returns the log-likelihood, and the quantity optimized
>    by the algorithm, which is the opposite of the log-likelihood, penalized.
>    A good common word for these two unrelated quantities was ""score"". In the
>    case of the log-likelihood, it matches scikit-learn's convention.

I'd call it ""..._scores"", in that case.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
73,pull_request_commit_comment,100,nilearn,nilearn,pgervais,2013-08-30 12:48:54,"I fixed this.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/tests/test_group_sparse_covariance.py')"
74,pull_request_commit_comment,100,nilearn,nilearn,bthirion,2013-09-03 17:17:31,"Then shouln't it be removed ?
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/_utils/testing.py')"
75,pull_request_commit_comment,100,nilearn,nilearn,bthirion,2013-09-03 17:24:37,"len(subjects) = n_subjects. n_samples varies according to the subject
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/_utils/testing.py')"
76,pull_request_commit_comment,100,nilearn,nilearn,bthirion,2013-09-03 17:28:53,"So density controls the sparsity of the square root or of the underlying Autoregresive model. May be this could be made more precise.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(142, '', u'nilearn/_utils/testing.py')"
77,pull_request_commit_comment,100,nilearn,nilearn,bthirion,2013-09-03 17:44:17," dtype=np.float
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
78,pull_request_commit_comment,100,nilearn,nilearn,GaelVaroquaux,2013-09-03 19:22:22,"Agreed, if it's not used, it should be removed.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/_utils/testing.py')"
79,pull_request_commit_comment,100,nilearn,nilearn,bthirion,2013-09-03 21:10:09,"Maybe a comment on Fortan / C ordering somewhere ? Sorry if I missed it.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
80,pull_request_commit_comment,100,nilearn,nilearn,bthirion,2013-09-03 21:15:22,"You call them empirical covariance matrices in other docstrings.
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'nilearn/group_sparse_covariance.py')"
81,pull_request_commit_comment,100,nilearn,nilearn,bthirion,2013-09-05 16:46:01,"Could the title be improved to be more explicit (\alpha=...)? 

Otherwise, the example runs well on my box
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'plot_adhd_covariance2.py')"
82,pull_request_commit_comment,100,nilearn,nilearn,bthirion,2013-09-11 21:19:22,"convergence
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'doc/developers/group_sparse_covariance.rst')"
83,pull_request_commit_comment,100,nilearn,nilearn,bthirion,2013-09-11 21:22:01,"criterion
",a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,"(None, '', u'doc/developers/group_sparse_covariance.rst')"
84,pull_request_commit,100,nilearn,nilearn,pgervais,2013-06-04 12:34:22,First steps on Honorio-Samaras algorithm,b2ebc1d32a4e98c6030c9a1ebf5374da3d0e2e77,
85,pull_request_commit,100,nilearn,nilearn,pgervais,2013-06-05 07:54:54,"Test signals generator

Code for main algorithm has been completed, but not tested (it has not
been run at all).",5d45f91146e9ee822ad3db651748d4bd1491fbc1,
86,pull_request_commit,100,nilearn,nilearn,pgervais,2013-06-05 14:06:07,"Corrected some bugs in Newton-Raphson step

Adapted the formula to enforce a positive solution.
The formula used for the second derivative contained an error (bad
sign).",bc18fac522e36fff3c84f1674dad7faafd7215e4,
87,pull_request_commit,100,nilearn,nilearn,pgervais,2013-06-07 12:55:09,"Algorithm works on test case.

In the current state, the algorithm converges for different test cases.

The function contains **much** code for testing and asserting, that slows
down things a lot.",a8a6866532a258c949fe7f258b0da38b4691fe85,
88,pull_request_commit,100,nilearn,nilearn,pgervais,2013-06-07 14:18:30,"Added a debugging flag

Removed some test code.",7d19b206fd66bffd2f47ae3ebc67b8f61c106a45,
89,pull_request_commit,100,nilearn,nilearn,pgervais,2013-06-19 08:39:00,"Working example of honorio-samaras algorithm

This example is really rough, and there is debugging code everywhere.
But this state works.",6ec0d156811feec1ac48c11471e874840e333e33,
90,pull_request_commit,100,nilearn,nilearn,pgervais,2013-06-19 10:57:58,Code cleanup,cc6bfa3afdd7f61f1338a7e85874f7649e67d4f8,
91,pull_request_commit,100,nilearn,nilearn,pgervais,2013-06-19 15:54:09,Optimized Newton-Raphson step.,a62c134e800b14666da14e7ffa82bb7f91f9b2cb,
92,pull_request_commit,100,nilearn,nilearn,pgervais,2013-06-20 09:23:25,Reduced memory consumption in _detrend,cfff05b8fa02cf32bf0649a140e4674fe2bc836d,
93,pull_request_commit,100,nilearn,nilearn,pgervais,2013-06-20 13:36:55,"Reduced memory usage in _detrend, again

This memory usage reduction applies to all cases, instead of the previous
commit which improved a corner case.",ebb0b14b53bb09d9b56152bc6c41e905836b0dd2,
94,pull_request_commit,100,nilearn,nilearn,pgervais,2013-06-20 14:12:49,"Created _mean_of_squares

This function will replace a similar computation in high_variance_confounds()
which uses much more memory (execution time is similar, if not smaller).",5148cb88e7a79daf05ae38c99cdd9278031f191b,
95,pull_request_commit,100,nilearn,nilearn,pgervais,2013-06-20 15:00:04,Lower memory usage for high_variance_confound,6aac7dc51949557a59cae7bac20f906b70eb4ccd,
96,pull_request_commit,100,nilearn,nilearn,pgervais,2013-06-20 16:02:09,"Improved performance of H-S algorithm implementation

Replaced a loop by a numpy operation. Around 15% speedup on
plot_adhd_covariance2.py with 40 subjects.",d355f7fa74f8dd03b2e431b80b1a59c3bae70740,
97,pull_request_commit,100,nilearn,nilearn,pgervais,2013-06-21 15:02:14,Solved remaining problems after merging.,07a4b00b4260d856fb3d33bdfbcd7096531f1f77,
98,pull_request_commit,100,nilearn,nilearn,pgervais,2013-06-24 11:30:27,"Renamed honorio_samaras function

New name: group_spare_covariance()
Updated docstring.",97d75f47274b8d7e0e5b235346149da0bae9fc79,
99,pull_request_commit,100,nilearn,nilearn,pgervais,2013-06-24 15:50:40,"Added a test for group_sparse_covariance

Big code cleanup",a5491161e989fb340ae71b64e248c92d58545e43,
100,pull_request_commit,100,nilearn,nilearn,pgervais,2013-06-24 16:31:22,"Another optimization in group_sparse_covariance

The computation of an matrix inverse has been replaced by a computation
based on Sherman-Woodbury-Morrison formula. This improves the asymptotic
running time for a large number of variables.",f4b35bfb76d4bc1c0518f2a380883c463a6b03ad,
101,pull_request_commit,100,nilearn,nilearn,pgervais,2013-06-25 11:43:00,"group_sparse_covariance takes signals as input

The group_sparse_covariance() signature has been changed, to be
consistent with that of analogous functions in scikit-learn.

Added tests for group_sparse_covariance, adapted every example.",135137e76e96c27f6fa91ba642a08d5f5b781604,
102,pull_request_commit,100,nilearn,nilearn,pgervais,2013-06-25 13:09:12,"Created GroupSparseCovariance

Improved user messages in group_sparse_covariance
Moved LogMixin out of nifti_region.py.",78b5af702062b32f26b1ffbb37b0ba7b3534c682,
103,pull_request_commit,100,nilearn,nilearn,pgervais,2013-06-26 13:55:28,"Added duality gap computation

The return_costs keyword of group_sparse_covariance nows returns the
duality gap in addition to the primal problem cost.",38425e0d05eebb1d807329cf62ccc3cba2244dee,
104,pull_request_commit,100,nilearn,nilearn,pgervais,2013-06-26 15:07:52,"Small optimization of cost computation

duality gap and objective in group_sparse_covariance are now computed
inside a single function. This is faster than the previous two-function
implementation.",57674cc1f9f5940f0958c05166fa94427970b5af,
105,pull_request_commit,100,nilearn,nilearn,pgervais,2013-07-01 12:26:16,"Added duality gap and rho max computations

Duality gap is computed with return_costs=True.

rho max is the value of the regularization parameter above which the
resulting matrix is completely sparse (will be useful for cross-validated
estimator)",9d3c538a6505eb9911d589345cc803a9686bcf99,
106,pull_request_commit,100,nilearn,nilearn,pgervais,2013-07-02 11:12:33,First implementation of GroupSparseCovarianceCV,3317621c983fd8b37044babf8bba56dc15eda8c5,
107,pull_request_commit,100,nilearn,nilearn,pgervais,2013-07-02 11:49:44,Parallel computation in GroupSparseCovarianceCV,80e94afa47296efd32a720686eca3c6d327d95e3,
108,pull_request_commit,100,nilearn,nilearn,pgervais,2013-07-03 08:10:46,"Better duality gap computation

The computation now seems to always give positive duality gap.",d8a93d56b46b36cee1638689ded8689a1c2db647,
109,pull_request_commit,100,nilearn,nilearn,pgervais,2013-07-03 08:39:56,"Added tolerance-based stop criterion

The duality gap is compared to a tolerance value. Computation is
stopped if gap is smaller than tolerance.",75cb98341a947f3c98cbeaa84fba8e81bfbc4bb2,
110,pull_request_commit,100,nilearn,nilearn,pgervais,2013-07-03 11:23:34,"Added tests for GroupSparseCovariance(CV)

Corrected some bugs thanks to the tests.",f96449e777d8640f4a4890ec9a7350a32c72448b,
111,pull_request_commit,100,nilearn,nilearn,pgervais,2013-07-03 14:06:09,"Added a warning in group_sparse_covariance

A warning is issued when tolerance is not reached with the prescribed
number of iterations.",eb1e104bdb91ffa723b279b8b94b5d152b9924d4,
112,pull_request_commit,100,nilearn,nilearn,pgervais,2013-07-03 14:30:02,Tiny optimization: saved some memory allocation.,47e695e2a7edbcbb995e7d65605b13cdb4fa63b0,
113,pull_request_commit,100,nilearn,nilearn,pgervais,2013-07-03 15:28:15,Fixed a spurious warning in a test,df24ce4278d4e2073590fd44b72083711a4dfc58,
114,pull_request_commit,100,nilearn,nilearn,pgervais,2013-07-03 16:08:55,"Reorganized code

Split group_sparse_covariance in two functions: one that takes signals
as input (for users) and one that takes empirical covariances (for
internal usage). This prepares for some more optimization of the
cross-validation function.",e38173bfb42c91a5261c06dcfbe0b8a2389e1137,
115,pull_request_commit,100,nilearn,nilearn,pgervais,2013-07-09 16:03:18,"Improved GroupSparseCovarianceCV (faster)

Used restart value to (slightly) reduce convergence time.

Updated documentation
Added functions to generate test signals.",264cad6cd6e30cd28db7bb2dacc1990bf1451486,
116,pull_request_commit,100,nilearn,nilearn,pgervais,2013-07-10 12:10:41,"Duality gap is not inf anymore

In some cases where the empirical covariance matrices were singular,
the duality gap as computed previously could take infinite values. This
has been fixed by computing another feasible dual point in such cases.
The computed value is not a tight bound, but it is believed to be only
useful far from the optimum.

Added objective value in user messages during computation.",7e4088911a4bb4ef4616d0fce041e2f3de0e201a,
117,pull_request_commit,100,nilearn,nilearn,pgervais,2013-07-10 16:00:55,Corrected a bug in signals generation,5c542cb39b113998487bbb4d12a5cd71b7298b24,
118,pull_request_commit,100,nilearn,nilearn,pgervais,2013-07-18 14:57:01,Intermediate possibly buggy state,c8c2a2376b87e0f7f1cd7d6b83fbe07dcd3639d4,
119,pull_request_commit,100,nilearn,nilearn,pgervais,2013-07-19 16:14:33,"Updated generate_sparse_precision_matrix

Added an option to get an corresponding covariance matrix with
only ones on the diagonal.",8275f2a88a59029c36037c1370b13f28fdb88106,
120,pull_request_commit,100,nilearn,nilearn,pgervais,2013-07-19 16:15:41,"Optimized Newton-Raphson step.

Dropped dependence on scipy for Newton-Raphson.",e227e8217c6e52d1be6389f8b86f8a31e886e6f1,
121,pull_request_commit,100,nilearn,nilearn,pgervais,2013-07-19 16:17:07,Code cleanup,b2f238ebd2cb4479908ff88224e193865291ab8f,
122,pull_request_commit,100,nilearn,nilearn,pgervais,2013-07-31 13:11:40,Time is returned along with costs,e04fa90c00318a1d62d1695e9eb4a113872de63c,
123,pull_request_commit,100,nilearn,nilearn,pgervais,2013-07-31 14:43:50,"Changed stopping criterion

Iterations are now stopped when all coefficients in the estimated
precision matrix change less than the tolerance between two
iterations.
This gives kind of a guaranteed number of decimals in the estimated
precision matrices.",82441ec271984fe43d070a6bfca029f5bc5f3536,
124,pull_request_commit,100,nilearn,nilearn,pgervais,2013-07-31 15:43:33,Minor bug fix.,4fd4d669dc5955258790c1bb809338894cfe0a16,
125,pull_request_commit,100,nilearn,nilearn,pgervais,2013-08-01 09:18:33,"Probing of group_sparse_covariance

Added keyword ""probe_function"" to group_sparse_covariance. This is a
way to provide a function that is called after each iteration. See
aspect-oriented programming.

Updated the standard message displayed for each iteration, to show the
max norm of the difference between two estimation of the precision
matrices.",a95ecb3bec35d74a08bf3ea83d1d1ac8b8fd26b3,
126,pull_request_commit,100,nilearn,nilearn,pgervais,2013-08-01 12:24:47,"Remove ""return_costs"" keyword

This keyword is useless because the same feature can be obtained using
a probe.",7fa05c75129a7250300ab4d7e701db2149fb9764,
127,pull_request_commit,100,nilearn,nilearn,pgervais,2013-08-01 13:46:23,"Code cleanup

Almost every ""dtype"" keyword argument has been removed.",cba4e0ecaa5a4ef3c879fd9319b4220dee85db64,
128,pull_request_commit,100,nilearn,nilearn,pgervais,2013-08-01 15:08:27,"Optimized group_sparse_covariance()

Gained 20% execution time on a particular case (mainly in the Newton-
Raphson part)",b1643a9132eda07ab638bdb12a9325d61af54010,
129,pull_request_commit,100,nilearn,nilearn,pgervais,2013-08-01 15:23:22,"One more small optimization in GSC.

GSC: group_sparse_covariance",2afa244b4444a6d424cbd546bbf11fe7a42a5381,
130,pull_request_commit,100,nilearn,nilearn,pgervais,2013-08-26 15:22:57,"Fixed an import bug.

Added some documentation to group_sparse_covariance()",f9119317c63e14a5c31aa10153691b869d380a04,
131,pull_request_commit,100,nilearn,nilearn,pgervais,2013-08-28 07:54:06,Arguments passed to probe function are correct now,a4dd1f784b7e03823b547a41ea1adf54fc840578,
132,pull_request_commit,100,nilearn,nilearn,pgervais,2013-08-29 11:23:25,"Added early stopping to GroupSparseCovarianceCV

Early stopping also to run cross-validation code faster, by stopping
iteration before reaching convergence according to maximum norm.

group_sparse_score output has been modified: the first value is now
the log-likelihood on test set (instead of the opposite of it: the
sign was changed).

Updated docstrings.",d85db4f8a0abf49f9370202803c3922da05af6f4,
133,pull_request_commit,100,nilearn,nilearn,pgervais,2013-08-29 14:00:57,Code cleanup,d5a32175fcb5d029c34fbfc7621ad2b025fc7616,
134,pull_request_commit,100,nilearn,nilearn,pgervais,2013-08-29 15:06:32,"Started renaming ""rho"" to ""alpha""

Got rid of conflicting usage of the ""alpha"" name.",544ceaee84578be6cef415d1272e226e54cdb5c4,
135,pull_request_commit,100,nilearn,nilearn,pgervais,2013-08-29 16:21:16,"Code refactoring

- Renamings: task->subject, rho->alpha.
- Fixed a lot of docstrings
- Removed some constructs not compatible with Python 3 (xrange)
- Refactored plot_adhd_covariance2 a lot. Now shorter and much clearer.
- Replaced numpy.linalg.inv by scipy.linalg.inv",363cb21af01cd3c86067882b98eb08e6f4a33a75,
136,pull_request_commit,100,nilearn,nilearn,pgervais,2013-08-30 11:31:19,"Renamed internal variable

Winv -> W_inv",91c9d2756f4287bb4293f27b7c1a348dcece419f,
137,pull_request_commit,100,nilearn,nilearn,pgervais,2013-08-30 12:12:46,"Code cleanup (doc, api)

group_sparse_score() renamed to group_sparse_scores() (added an S)",239f2fff548e15f5cb595c48f657427c6af96703,
138,pull_request_commit,100,nilearn,nilearn,pgervais,2013-08-30 12:44:36,"Code simplification and cleanup

Replace some custom code by sklearn.utils.gen_even_slices",5b3cf6f005d0461c770f5fedf5e546859cab4e71,
139,pull_request_commit,100,nilearn,nilearn,pgervais,2013-08-30 15:08:14,"Got rid of spurious warning in tests

Docstring and comments fixes.",adf52e0c61e74ac05e8c40f3f706edede4eb6926,
140,pull_request_commit,100,nilearn,nilearn,pgervais,2013-08-30 15:18:27,generate_group_sparse_gaussian_graphs() in testing,ed8731343cf8374b9603e93f251abde4b6166139,
141,pull_request_commit,100,nilearn,nilearn,pgervais,2013-09-02 13:09:58,"Improved numerical stability

Added two lines to force symmetric at the end of _update_submatrix.

Some cleanup.",d8590f94ae7afaec4a6228c93d4c688d57965f38,
142,pull_request_commit,100,nilearn,nilearn,pgervais,2013-09-02 13:32:01,"Merge branch 'master' into honorio_samaras

Conflicts:
	nilearn/input_data/nifti_region.py
	nilearn/tests/__init__.py",0867b2b579f8622b31453078601e66afe21f3ae9,
143,pull_request_commit,100,nilearn,nilearn,pgervais,2013-09-02 13:41:39,group_sparse_covariance uses logger.log(),544d3a9801c975462fa3bd6c8cf8d3472170487d,
144,pull_request_commit,100,nilearn,nilearn,pgervais,2013-09-02 13:43:40,Remove LogMixin class.,160b8590da99f8b94b054e47e1e2ba01c0aee2b5,
145,pull_request_commit,100,nilearn,nilearn,pgervais,2013-09-02 14:06:49,Code cleanup,a2a0f549159b18ad9e724c79b19494e8c7426447,
146,pull_request_commit,100,nilearn,nilearn,pgervais,2013-09-04 07:42:00,Code cleanup,13bdc45a39182b911bdb7ebe848bf3f95085c070,
147,pull_request_commit,100,nilearn,nilearn,pgervais,2013-09-04 16:28:42,Small docstring fixes,43c24627d31f22ea2f7c9e462ff23dd309dab2f0,
148,pull_request_commit,100,nilearn,nilearn,pgervais,2013-09-05 10:54:13,"Added a technical documentation page

The documentation is about the group sparse covariance algorithm.
No link to it has been added in index.rst yet.",fca0ea9168e6b3a14b6280f7adc11719f84f19af,
149,pull_request_commit,100,nilearn,nilearn,pgervais,2013-09-06 09:20:30,Merged graph lasso and group-sparse examples,c2d820df13a3f91f6407b428cb67c0e1b18413f9,
150,pull_request_commit,100,nilearn,nilearn,pgervais,2013-09-06 09:28:47,"""standardize"" keyword for empirical_covariances

Standardizing time series is required for numerical stability of group-
sparse covariance optimization. This is technically useful for the
cross-validated version.",6ec7e60209b776aaef9dd52437a19d29aecf8f4b,
151,pull_request_commit,100,nilearn,nilearn,pgervais,2013-09-06 12:48:46,"[DOC] group-sparse covariance

Added information of parallelism, grid search and warm restart.",ac7c0dee779218197305780f866ef96802b0761d,
152,pull_request_commit,100,nilearn,nilearn,pgervais,2013-09-06 13:58:46,"Clean up duality gap computation

Move duality gap computation into group_sparse_scores().

Group-sparse covariance estimation is now always performed in
double precision.",c7af1f34d7cbecf347b3039f962b33980e226265,
153,pull_request_commit,100,nilearn,nilearn,pgervais,2013-09-09 08:28:57,"Separated convergence parameters in CV

In GroupSparseCovarianceCV, tolerance and maximum iteration number can
have different values for the alpha selection phase, and the final
optimization. Two keywords have been added: tol_cv and max_iter_cv.",5ee35b3def2d7b1e15b65b626d406b8da1e5682f,
154,pull_request_commit,100,nilearn,nilearn,pgervais,2013-09-10 12:50:51,Example comparing sparse precision estimation,35c8a5d57ac877e47041d9e2e64c779bfae0de11,
155,pull_request_commit,100,nilearn,nilearn,pgervais,2013-09-10 12:59:17,"Removed ""assume_centered"" keyword in g.s.c.

The ""assume_centered"" keyword has been removed from every function
related to group-sparse covariance (useless).",63375299bad2c7374d372d1ce17228354f187a71,
156,pull_request_commit,100,nilearn,nilearn,pgervais,2013-09-11 08:32:37,"[DOC] fixed paragraph on data extraction

plot_adhd_covariance.py example had changed a lot, the rst file was
referencing lines that didn't exist anymore.",2b2a15c8e2b156b35fa66130876a5a77e87d4489,
157,pull_request_commit,100,nilearn,nilearn,pgervais,2013-09-11 12:01:39,[BUG] compatibility with sklearn 0.10-0.14,8acb04971d8f06887521fbdc6a17589390003c79,
158,pull_request_commit,100,nilearn,nilearn,pgervais,2013-09-11 12:38:11,"[DOC] functional connectivity page

And a page on the technical aspects of the group-sparse covariance
implementation.

Also fixed some bugs.",47bddb156c7406532560b7c679e430606a162de0,
159,pull_request_commit,100,nilearn,nilearn,pgervais,2013-09-11 13:06:11,"Merge branch 'master' into honorio_samaras

Conflicts:
	doc/index.rst",33f19ea7355c58237cd07fa2ef4b48d09bca4850,
160,pull_request_commit,100,nilearn,nilearn,pgervais,2013-09-11 13:34:35,"[TST] Fix failing test

A test is failing on Travis (np.diff(objective) <= 0 in
test_group_sparse_covariance.py:51), that does not occur of the
developer's machine. np.diff(objective) may be hitting the numerical
noise floor (1e-14 or so). Some values may then be slightly positive.
This is most probably due to a different numerical library which leads to
a slightly different result.

The fix consists in decreasing the number of iterations so that optimization
stops before hitting the noise floor.",8647d78eff16492804d460e5666e91c9a8fb9ea5,
161,pull_request_commit,100,nilearn,nilearn,pgervais,2013-09-13 07:39:01,[DOC] fixed some typos,a895fded9e5cc73dd3ce7f03c1896e1fbf7d83ce,
162,pull_request_commit_comment,100,nilearn,nilearn,bthirion,2013-09-11 21:08:06,"gives
",47bddb156c7406532560b7c679e430606a162de0,"(152, 152, u'doc/functional_connectivity.rst')"
