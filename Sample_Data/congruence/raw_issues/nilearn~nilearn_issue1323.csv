"rectype","issueid","project_owner","project_name","actor","time","text","action","title"
"issue_title","1323","nilearn","nilearn","dawnsong","2016-11-05 04:05:29","Dear Dr. Gaël and Arthur, 

The reference given in the help and code of diction learning is:
Gaël Varoquaux, Gramfort, A., Pedregosa, F., Michel, V., Thirion, B., 2011. Multi-subject dictionary learning to segment an atlas of brain spontaneous activity, in: Information Processing in Medical Imaging. Springer, pp. 562–573.


But after reading the code, it looks like the reference should be:
Mensch, A., Varoquaux, G., Thirion, B., 2016. Compressed online dictionary learning for fast resting-state fMRI decomposition, in: 2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI). Presented at the 2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI), pp. 1282–1285. doi:10.1109/ ISBI.2016.7493501

Am I correct? If I am correct, will you also include MSDL method into nilearn in future?

Best,
Xiaowei

Reference:

- [nilearn dictionary learning help](http://nilearn.github.io/auto_examples/03_connectivity/plot_compare_resting_state_decomposition.html)

- [nilearn dictionary learning code](https://github.com/nilearn/nilearn/blob/master/nilearn/decomposition/dict_learning.py)","start issue","Wrong reference for dictionary learning in current nilearn?"
"issue_closed","1323","nilearn","nilearn","KamalakerDadi","2017-03-03 15:57:10","","closed issue","Wrong reference for dictionary learning in current nilearn?"
"issue_comment","1323","nilearn","nilearn","GaelVaroquaux","2016-11-07 06:12:46","Xiaowei is right, and the code that we use is actually pretty much the
paper by Arthur in ISBI.

The MSDL is much more complicated to code, and is still in the pipeline
:(. It's also much slower.
","",""
"issue_comment","1323","nilearn","nilearn","bthirion","2016-11-06 22:07:01","You probably mean that the Varoquaux method in 2011 wans not an online version. I'm not sure that the implementation here uses the tricks of the ISBI paper though. 
@arthurmensch can you confirm ?
","",""
"issue_comment","1323","nilearn","nilearn","dawnsong","2016-11-07 00:58:27","Thanks for your response, Prof. Thirion, @bthirion .
I guess batch/online might be also one difference, as you pointed out, but I don't know where to download and try MSDL.
In the current ""dict_learning.py"", the penalty is only L-1 norm (from sklearn's Dictionary Learning), not like Varoquax's MSDL, which used smooth-Lasso. 
And the current ""dict_learning.py"" feed DL  with PCA reduced in subject-level and temporal-concatenated to group level. While MSDL's cost fucntion directly modeled subject's data, does not use PCA to reduce subject's data. I guess it is very similar and should be Arthur's 2016 ISBI paper.

Best,
Xiaowei
","",""
"issue_comment","1323","nilearn","nilearn","dawnsong","2016-11-07 06:31:18","Dear Dr. Varoquaux, @GaelVaroquaux , thanks a lot for confirmation :)
The current Arthur's online DL version is lightning fast for my test data!
","",""
