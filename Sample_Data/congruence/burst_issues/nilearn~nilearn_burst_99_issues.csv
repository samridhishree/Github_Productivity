,rectype,issueid,project_owner,project_name,actor,time,text,action,title
0,rectype,issueid,project_owner,project_name,actor,time,text,action,title
1,issue_title,1355,nilearn,nilearn,GaelVaroquaux,2017-01-11 10:26:36,"It seems that memprofiler is now Pyhon2.6 incompatible. We should drop the Python 2.6 support.

* [ ] Grep the code for ""2.6"" and change everything to 2.7 or remove
* [ ] Related: in nilearn/version.py, we should now use an OrderedDict
* [ ] switch travis",start issue,Drop Python 2.6 compatibility
2,issue_closed,1355,nilearn,nilearn,AlexandreAbraham,2017-01-20 09:00:30,,closed issue,Drop Python 2.6 compatibility
0,rectype,issueid,project_owner,project_name,actor,time,text,action,title
1,issue_title,1360,nilearn,nilearn,GaelVaroquaux,2017-01-20 16:54:37,scipy 0.17.1 is what neurodebian has,start issue,[MRG] MAINT: adjust versions on CI
2,issue_closed,1360,nilearn,nilearn,GaelVaroquaux,2017-01-21 10:48:36,,closed issue,[MRG] MAINT: adjust versions on CI
3,pull_request_title,1360,nilearn,nilearn,GaelVaroquaux,2017-01-20 16:54:37,scipy 0.17.1 is what neurodebian has,6837c19faa5a11f6cc3a59c6d2575f1809863710,[MRG] MAINT: adjust versions on CI
4,pull_request_merged,1360,nilearn,nilearn,GaelVaroquaux,2017-01-21 10:48:36,[MRG] MAINT: adjust versions on CI,ffbded325bc5a7d2141aab325942b3b78eff4e2a,Pull request merge from GaelVaroquaux/nilearn:remove_py26 to nilearn/nilearn:master
5,pull_request_commit,1360,nilearn,nilearn,GaelVaroquaux,2017-01-20 00:13:18,MAINT: try to fix deps in CI,6837c19faa5a11f6cc3a59c6d2575f1809863710,
0,rectype,issueid,project_owner,project_name,actor,time,text,action,title
1,issue_title,1359,nilearn,nilearn,GaelVaroquaux,2017-01-20 00:12:42,Slightly more didactic docs,start issue,[MRG + 1] DOC
2,issue_closed,1359,nilearn,nilearn,GaelVaroquaux,2017-01-22 08:55:35,,closed issue,[MRG + 1] DOC
3,pull_request_title,1359,nilearn,nilearn,GaelVaroquaux,2017-01-20 00:12:42,Slightly more didactic docs,c8b4914f7ea1ba5e329841445a957ed90bd25651,[MRG + 1] DOC
4,pull_request_merged,1359,nilearn,nilearn,GaelVaroquaux,2017-01-22 08:55:35,[MRG + 1] DOC,c42699ac7bbd24525fa4787706bdad7d939e61de,Pull request merge from GaelVaroquaux/nilearn:rephrase_docs to nilearn/nilearn:master
5,pull_request_commit_comment,1359,nilearn,nilearn,bthirion,2017-01-20 09:05:17,response,c8b4914f7ea1ba5e329841445a957ed90bd25651,"(None, '', u'doc/decoding/decoding_intro.rst')"
6,pull_request_commit_comment,1359,nilearn,nilearn,bthirion,2017-01-20 09:08:00,'downloading and returning' or 'download and return',c8b4914f7ea1ba5e329841445a957ed90bd25651,"(None, '', u'doc/decoding/decoding_intro.rst')"
7,pull_request_commit_comment,1359,nilearn,nilearn,bthirion,2017-01-20 09:13:49,time,c8b4914f7ea1ba5e329841445a957ed90bd25651,"(None, '', u'doc/decoding/decoding_intro.rst')"
8,pull_request_commit_comment,1359,nilearn,nilearn,KamalakerDadi,2017-01-21 16:07:51,disriminating -> discr,c8b4914f7ea1ba5e329841445a957ed90bd25651,"(None, '', u'doc/decoding/decoding_intro.rst')"
9,pull_request_commit_comment,1359,nilearn,nilearn,KamalakerDadi,2017-01-21 16:08:05,Aera -> Area,c8b4914f7ea1ba5e329841445a957ed90bd25651,"(None, '', u'doc/decoding/decoding_intro.rst')"
10,pull_request_commit_comment,1359,nilearn,nilearn,KamalakerDadi,2017-01-21 16:08:22,Reciever -> Reciever,c8b4914f7ea1ba5e329841445a957ed90bd25651,"(None, '', u'doc/decoding/decoding_intro.rst')"
11,pull_request_commit_comment,1359,nilearn,nilearn,KamalakerDadi,2017-01-21 16:09:24,understood -> understand,c8b4914f7ea1ba5e329841445a957ed90bd25651,"(None, '', u'doc/decoding/estimator_choice.rst')"
12,pull_request_commit_comment,1359,nilearn,nilearn,KamalakerDadi,2017-01-21 16:09:56,similations -> simulations,c8b4914f7ea1ba5e329841445a957ed90bd25651,"(None, '', u'doc/decoding/estimator_choice.rst')"
13,pull_request_commit_comment,1359,nilearn,nilearn,KamalakerDadi,2017-01-21 16:19:13,places -> animals,c8b4914f7ea1ba5e329841445a957ed90bd25651,"(16, '', u'examples/02_decoding/plot_haxby_anova_svm.py')"
14,pull_request_commit_comment,1359,nilearn,nilearn,KamalakerDadi,2017-01-21 16:20:33,"USe -> Use
anatomic -> anatomical",c8b4914f7ea1ba5e329841445a957ed90bd25651,"(None, '', u'examples/02_decoding/plot_haxby_anova_svm.py')"
15,pull_request_commit,1359,nilearn,nilearn,GaelVaroquaux,2017-01-19 22:49:18,"DOC:

Slightly more didactic docs",f85affd0f4ef48f8f565baabb222299b785e561a,
16,pull_request_commit,1359,nilearn,nilearn,GaelVaroquaux,2017-01-20 18:26:12,"DOC: better example to teach

- Use ""masker"" as it is the name that we use in other example (makes
  it easier to copy-paste code to an ipython notebook in which another
  example has been run)

- Do visualization after cross-validation",48e069943706cd971aa1c3bc561f8288f69d3d53,
17,pull_request_commit,1359,nilearn,nilearn,GaelVaroquaux,2017-01-20 18:31:53,"DOC: simpler example, more didactic",6e759fb0add81d564062b435afd58177147e42c8,
18,pull_request_commit,1359,nilearn,nilearn,GaelVaroquaux,2017-01-20 19:34:36,DOC: more uniform vocabulary in examples,d019b41e17e350f0631cd6156f2ffb5dffb8bc93,
19,pull_request_commit,1359,nilearn,nilearn,GaelVaroquaux,2017-01-20 20:38:06,"DOC: move decoding on simulation to an example

With the notebook-style examples, it is now possible to put enough text
in an example that we do not need this in a full documentation's section.",4344b45bce098e786da376dec458b369fc9fa172,
20,pull_request_commit,1359,nilearn,nilearn,GaelVaroquaux,2017-01-20 20:52:16,Address comments by @bthirion,dc1e87b40b3f07c29d019fd177dd04a691b65414,
21,pull_request_commit,1359,nilearn,nilearn,GaelVaroquaux,2017-01-21 17:25:53,Address @KamalakerDadi's comments,c8b4914f7ea1ba5e329841445a957ed90bd25651,
0,rectype,issueid,project_owner,project_name,actor,time,text,action,title
1,issue_title,1367,nilearn,nilearn,ant1hu8,2017-01-25 15:51:10,"Hi guys, I have a problem with the part in which we prepare the fMRI file in exercice 8.3.7 (http://nilearn.github.io/auto_examples/02_decoding/plot_haxby_anova_svm.html#sphx-glr-auto-examples-02-decoding-plot-haxby-anova-svm-py) and I do not understand the error message. I downloaded several time the ipynb file (I use ipython notebook) but the error is still appearing : 

`C:\Users\Antoine Huet\Anaconda2\lib\site-packages\sklearn\externals\joblib\hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by
descriptor assignment is deprecated. To maintain
the Fortran contiguity of a multidimensional Fortran
array, use 'a.T.view(...).T' instead
  obj_bytes_view = obj.view(self.np.uint8)
C:\Users\Antoine Huet\Anaconda2\lib\site-packages\sklearn\externals\joblib\hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by
descriptor assignment is deprecated. To maintain
the Fortran contiguity of a multidimensional Fortran
array, use 'a.T.view(...).T' instead
  obj_bytes_view = obj.view(self.np.uint8)`

Could someone explain what the error is actually meaning?",start issue,Problem preparing the fMRI data in Decoding with ANOVA + SVM exercice
2,issue_closed,1367,nilearn,nilearn,GaelVaroquaux,2017-01-25 17:19:55,,closed issue,Problem preparing the fMRI data in Decoding with ANOVA + SVM exercice
3,issue_comment,1367,nilearn,nilearn,ant1hu8,2017-01-25 16:18:42,"Thank you @GaelVaroquaux, however I did not wait enough time apparently because I got this printed below the warning I uploaded :

`ValueError                                Traceback (most recent call last)
<ipython-input-18-98e67f4284b7> in <module>()
     13                            memory=""nilearn_cache"", memory_level=1)
     14 func_filename = haxby_dataset.func[0]
---> 15 X = nifti_masker.fit_transform(func_filename)
     16 # Apply our condition_mask (apply the nifti_masker to func_filename)
     17 X = X[condition_mask]

C:\Users\Antoine Huet\AppData\Roaming\Python\Python27\site-packages\nilearn\input_data\base_masker.pyc in fit_transform(self, X, y, confounds, **fit_params)
    204                                 ).transform(X, confounds=confounds)
    205             else:
--> 206                 return self.fit(**fit_params).transform(X, confounds=confounds)
    207         else:
    208             # fit method of arity 2 (supervised transformation)

C:\Users\Antoine Huet\AppData\Roaming\Python\Python27\site-packages\nilearn\input_data\base_masker.pyc in transform(self, imgs, confounds)
    174         self._check_fitted()
    175 
--> 176         return self.transform_single_imgs(imgs, confounds)
    177 
    178     def fit_transform(self, X, y=None, confounds=None, **fit_params):

C:\Users\Antoine Huet\AppData\Roaming\Python\Python27\site-packages\nilearn\input_data\nifti_masker.pyc in transform_single_imgs(self, imgs, confounds, copy)
    291             verbose=self.verbose,
    292             confounds=confounds,
--> 293             copy=copy
    294         )
    295 

C:\Users\Antoine Huet\Anaconda2\lib\site-packages\sklearn\externals\joblib\memory.pyc in __call__(self, *args, **kwargs)
    481 
    482     def __call__(self, *args, **kwargs):
--> 483         return self._cached_call(args, kwargs)[0]
    484 
    485     def __reduce__(self):

C:\Users\Antoine Huet\Anaconda2\lib\site-packages\sklearn\externals\joblib\memory.pyc in _cached_call(self, args, kwargs)
    428                           'directory %s'
    429                         % (name, argument_hash, output_dir))
--> 430             out, metadata = self.call(*args, **kwargs)
    431             if self.mmap_mode is not None:
    432                 # Memmap the output at the first call to be consistent with

C:\Users\Antoine Huet\Anaconda2\lib\site-packages\sklearn\externals\joblib\memory.pyc in call(self, *args, **kwargs)
    673         if self._verbose > 0:
    674             print(format_call(self.func, args, kwargs))
--> 675         output = self.func(*args, **kwargs)
    676         self._persist_output(output, output_dir)
    677         duration = time.time() - start_time

C:\Users\Antoine Huet\AppData\Roaming\Python\Python27\site-packages\nilearn\input_data\nifti_masker.pyc in filter_and_mask(imgs, mask_img_, parameters, memory_level, memory, verbose, confounds, copy)
     51                                       memory=memory,
     52                                       verbose=verbose,
---> 53                                       confounds=confounds, copy=copy)
     54 
     55     # For _later_: missing value removal or imputing of missing data

C:\Users\Antoine Huet\AppData\Roaming\Python\Python27\site-packages\nilearn\input_data\base_masker.pyc in filter_and_extract(imgs, extraction_function, parameters, memory_level, memory, verbose, confounds, copy)
    118             high_pass=parameters['high_pass'],
    119             confounds=confounds,
--> 120             sessions=sessions)
    121 
    122     return region_signals, aux

C:\Users\Antoine Huet\Anaconda2\lib\site-packages\sklearn\externals\joblib\memory.pyc in __call__(self, *args, **kwargs)
    281 
    282     def __call__(self, *args, **kwargs):
--> 283         return self.func(*args, **kwargs)
    284 
    285     def call_and_shelve(self, *args, **kwargs):

C:\Users\Antoine Huet\AppData\Roaming\Python\Python27\site-packages\nilearn\signal.pyc in clean(signals, sessions, detrend, standardize, confounds, low_pass, high_pass, t_r)
    471             raise ValueError(('The length of the session vector (%i) '
    472                               'does not match the length of the signals (%i)')
--> 473                               % (len(sessions), len(signals)))
    474         for s in np.unique(sessions):
    475             session_confounds = None

ValueError: The length of the session vector (216) does not match the length of the signals (1452)`

Could you confirm it's just part of the warning? Or will it mess with the rest of the script?",,
4,issue_comment,1367,nilearn,nilearn,ant1hu8,2017-01-25 16:45:41,"Alright, found the error, as you said the condition_mask was only applied to part of the data. 
Thanks for your time @GaelVaroquaux  !",,
0,rectype,issueid,project_owner,project_name,actor,time,text,action,title
1,issue_title,1364,nilearn,nilearn,lrq3000,2017-01-25 13:19:41,"I have an issue while loading one sample dataset: I always get a MemoryError, even when I only try to draw a few slices for only one subject.

I reproduced this error on 3 different computers: 2 laptops with Windows 7 x64 and 4GB of RAM, and 1 research workstation with 16 GB.

I just installed nilearn on all these computers using `pip install nilearn`.

Here is the code used:

```
import nilearn
print(nilearn.__version__)

from nilearn import datasets

# By default 2nd subject will be fetched
haxby_dataset = datasets.fetch_haxby('datasets')

# print basic information on the dataset
print('Mask nifti image (3D) is located at: %s' % haxby_dataset.mask)
print('Functional nifti image (4D) is located at: %s' %
      haxby_dataset.func[0])

func_filename = 'datasets\\haxby2001\\subj1\\bold.nii.gz'

from nilearn.image import index_img
func_filename = index_img(haxby_dataset.func[0], slice(0,1))
func_filename
```

And here is the output:
```
0.2.6
Mask nifti image (3D) is located at: datasets\haxby2001\mask.nii.gz
Functional nifti image (4D) is located at: datasets\haxby2001\subj2\bold.nii.gz
---------------------------------------------------------------------------
MemoryError                               Traceback (most recent call last)
<ipython-input-1-92d8185ad49b> in <module>()
     15 
     16 from nilearn.image import index_img
---> 17 func_filename = index_img(haxby_dataset.func[0], slice(0,1))
     18 func_filename

C:\Anaconda2\lib\site-packages\nilearn\image\image.pyc in index_img(imgs, index)
    554     """"""
    555     imgs = check_niimg_4d(imgs)
--> 556     return _index_img(imgs, index)
    557 
    558 

C:\Anaconda2\lib\site-packages\nilearn\_utils\niimg_conversions.pyc in _index_img(img, index)
     72     """"""Helper function for check_niimg_4d.""""""
     73     return new_img_like(
---> 74         img, img.get_data()[:, :, :, index], get_affine(img),
     75         copy_header=True)
     76 

C:\Anaconda2\lib\site-packages\nibabel\spatialimages.pyc in get_data(self, caching)
    580         if self._data_cache is not None:
    581             return self._data_cache
--> 582         data = np.asanyarray(self._dataobj)
    583         if caching == 'fill':
    584             self._data_cache = data

C:\Anaconda2\lib\site-packages\numpy\core\numeric.pyc in asanyarray(a, dtype, order)
    523 
    524     """"""
--> 525     return array(a, dtype, copy=False, order=order, subok=True)
    526 
    527 def ascontiguousarray(a, dtype=None):

C:\Anaconda2\lib\site-packages\nibabel\arrayproxy.pyc in __array__(self)
    142     def __array__(self):
    143         # Read array and scale
--> 144         raw_data = self.get_unscaled()
    145         return apply_read_scaling(raw_data, self._slope, self._inter)
    146 

C:\Anaconda2\lib\site-packages\nibabel\arrayproxy.pyc in get_unscaled(self)
    137                                        offset=self._offset,
    138                                        order=self.order,
--> 139                                        mmap=self._mmap)
    140         return raw_data
    141 

C:\Anaconda2\lib\site-packages\nibabel\volumeutils.pyc in array_from_file(shape, in_dtype, infile, offset, order, mmap)
    515     if hasattr(infile, 'readinto'):
    516         data_bytes = bytearray(n_bytes)
--> 517         n_read = infile.readinto(data_bytes)
    518         needs_copy = False
    519     else:

C:\Anaconda2\lib\gzip.pyc in read(self, size)
    266             try:
    267                 while size > self.extrasize:
--> 268                     self._read(readsize)
    269                     readsize = min(self.max_read_chunk, readsize * 2)
    270             except EOFError:

C:\Anaconda2\lib\gzip.pyc in _read(self, size)
    317             raise EOFError, 'Reached EOF'
    318 
--> 319         uncompress = self.decompress.decompress(buf)
    320         self._add_read_data( uncompress )
    321 

MemoryError:
```

Any idea what is causing this and how to fix it? Thanks a lot for any suggestion!",start issue,Absurd MemoryError
2,issue_closed,1364,nilearn,nilearn,GaelVaroquaux,2017-01-25 14:52:31,,closed issue,Absurd MemoryError
3,issue_comment,1364,nilearn,nilearn,lrq3000,2017-02-09 11:53:10,"Haha, good to know!  ;)
",,
0,rectype,issueid,project_owner,project_name,actor,time,text,action,title
1,issue_title,1368,nilearn,nilearn,antogeo,2017-01-26 10:36:48,"Hello, 
Is there any nested CV planned to be implemented?
Best!",start issue,Nested CV
2,issue_closed,1368,nilearn,nilearn,mrahim,2017-03-02 15:03:13,,closed issue,Nested CV
3,issue_comment,1368,nilearn,nilearn,eickenberg,2017-01-26 10:47:11,"and independently, nested cross-validation can be done with scikit-learn. nilearn is not going to provide anything that already exists in scikit-learn.
But maybe your question was more specific?",,
4,issue_comment,1368,nilearn,nilearn,antogeo,2017-01-26 12:54:46,"Thank you for your quick responses! 
What I had in my mind was hyperparameter selection and is included in the #698 
Merci!",,
0,rectype,issueid,project_owner,project_name,actor,time,text,action,title
1,issue_title,1304,nilearn,nilearn,erramuzpe,2016-10-04 09:25:37,"Hi!

I was trying to plot a statmap using`plt.plot_glass_brain()`and using `vmin` and `vmax` parameters to force range the colorbar between 2 given values. `vmax` works fine, but I could not make the colorbar's lower values to adapt to `vmin` 's values (should I open an issue?). I came to the source and spotted this small bug, which has no relation with my first problem, but I think it was fine to solve. 

thanks!
",start issue,"Line correction; if vmax was None, no point on assigning"
2,issue_closed,1304,nilearn,nilearn,GaelVaroquaux,2017-01-19 10:44:19,,closed issue,"Line correction; if vmax was None, no point on assigning"
3,pull_request_title,1304,nilearn,nilearn,erramuzpe,2016-10-04 09:25:37,"Hi!

I was trying to plot a statmap using`plt.plot_glass_brain()`and using `vmin` and `vmax` parameters to force range the colorbar between 2 given values. `vmax` works fine, but I could not make the colorbar's lower values to adapt to `vmin` 's values (should I open an issue?). I came to the source and spotted this small bug, which has no relation with my first problem, but I think it was fine to solve. 

thanks!
",60f2bee6105019bc983aca58bab4b708da493176,"Line correction; if vmax was None, no point on assigning"
4,pull_request_merged,1304,nilearn,nilearn,GaelVaroquaux,2017-01-19 10:44:19,"Line correction; if vmax was None, no point on assigning",4e64e83c7fdcb633d1628cd3eb748a020ad375f6,Pull request merge from erramuzpe/nilearn:display_small_correction to nilearn/nilearn:master
5,issue_comment,1304,nilearn,nilearn,GaelVaroquaux,2017-01-19 10:43:22,"Indeed, this was indeed a bug. Merging. Thank you.",,
6,issue_comment,1304,nilearn,nilearn,erramuzpe,2016-10-04 14:05:50,"I won't open an issue since already have been reported in #1149 
",,
7,pull_request_commit,1304,nilearn,nilearn,erramuzpe,2016-10-04 09:20:13,"Line correction; if vmax was None, no point on assigning",f39c290627db1efa28890e73834f242fdf8a6e5f,
8,pull_request_commit,1304,nilearn,nilearn,erramuzpe,2016-10-17 08:41:26,Merge branch 'master' into display_small_correction,60f2bee6105019bc983aca58bab4b708da493176,
0,rectype,issueid,project_owner,project_name,actor,time,text,action,title
1,issue_title,1358,nilearn,nilearn,GaelVaroquaux,2017-01-20 00:06:43,"Fixes #1355.

I decided not to use the OrderedDict because it didn't make the code simpler.",start issue,Remove py26 and sklearn 0.14
2,issue_closed,1358,nilearn,nilearn,AlexandreAbraham,2017-01-20 09:00:30,,closed issue,Remove py26 and sklearn 0.14
3,pull_request_title,1358,nilearn,nilearn,GaelVaroquaux,2017-01-20 00:06:43,"Fixes #1355.

I decided not to use the OrderedDict because it didn't make the code simpler.",d2074a810f5ad74b7b538df9afa66b2c3172260a,Remove py26 and sklearn 0.14
4,pull_request_merged,1358,nilearn,nilearn,AlexandreAbraham,2017-01-20 09:00:30,Remove py26 and sklearn 0.14,64c2155da998161264e93b2208f10430755b77ac,Pull request merge from GaelVaroquaux/nilearn:remove_py26 to nilearn/nilearn:master
5,pull_request_commit,1358,nilearn,nilearn,GaelVaroquaux,2017-01-19 14:05:07,MAINT: drop support for Python 2.6,7e1975c99fcf71ac6b9b03be849ded9eab09e4f6,
6,pull_request_commit,1358,nilearn,nilearn,GaelVaroquaux,2017-01-19 14:56:05,"MAINT: drop support for sklearn 0.14

Oldest supported sklearn version is now 0.15",741bbacdcfd38e415ce7ef71b58f53247790ff2d,
7,pull_request_commit,1358,nilearn,nilearn,GaelVaroquaux,2017-01-20 00:13:18,MAINT: try to fix deps in CI,d2074a810f5ad74b7b538df9afa66b2c3172260a,
0,rectype,issueid,project_owner,project_name,actor,time,text,action,title
1,issue_title,1366,nilearn,nilearn,ahoyosid,2017-01-25 15:33:11,"With this PR we solve the issue #1365.
We separate the function that checks the memory in _utils/chache_mixin.py, and use it use it in check_embedded_nifti_masker.

Basically this functions returns a memory object with the predefine cachedir.

Ping @GaelVaroquaux  @KamalakerDadi ",start issue,Check memory
2,issue_closed,1366,nilearn,nilearn,GaelVaroquaux,2017-01-26 16:40:57,,closed issue,Check memory
3,pull_request_title,1366,nilearn,nilearn,ahoyosid,2017-01-25 15:33:11,"With this PR we solve the issue #1365.
We separate the function that checks the memory in _utils/chache_mixin.py, and use it use it in check_embedded_nifti_masker.

Basically this functions returns a memory object with the predefine cachedir.

Ping @GaelVaroquaux  @KamalakerDadi ",61b0221adf07ea8e96a78c271eb92466f23728b8,Check memory
4,pull_request_merged,1366,nilearn,nilearn,GaelVaroquaux,2017-01-26 16:40:57,Check memory,31e4b55c0e196b8de83c3e96087f943c45f3ec20,Pull request merge from ahoyosid/nilearn:check_memory to nilearn/nilearn:master
5,pull_request_commit_comment,1366,nilearn,nilearn,GaelVaroquaux,2017-01-26 14:44:42,"A tiny docstring would really help. In particular detailing the accepted types of the memory argument, as this is non trivial.",61b0221adf07ea8e96a78c271eb92466f23728b8,"(None, '', u'nilearn/_utils/cache_mixin.py')"
6,pull_request_commit_comment,1366,nilearn,nilearn,GaelVaroquaux,2017-01-26 15:55:38,"The function also accepts None, doesn't it?",61b0221adf07ea8e96a78c271eb92466f23728b8,"(None, '', u'nilearn/_utils/cache_mixin.py')"
7,pull_request_commit_comment,1366,nilearn,nilearn,KamalakerDadi,2017-01-27 13:19:10,default is 0 but you mentioned as 1,61b0221adf07ea8e96a78c271eb92466f23728b8,"(14, '', u'nilearn/_utils/cache_mixin.py')"
8,pull_request_commit_comment,1366,nilearn,nilearn,ahoyosid,2017-01-27 13:20:51,"Oh, that's true...
It's is already merged. Do you know how can I change this?",61b0221adf07ea8e96a78c271eb92466f23728b8,"(14, '', u'nilearn/_utils/cache_mixin.py')"
9,pull_request_commit_comment,1366,nilearn,nilearn,KamalakerDadi,2017-01-27 13:21:32,Function to make ensure an instance of joblib memory object.,61b0221adf07ea8e96a78c271eb92466f23728b8,"(5, '', u'nilearn/_utils/cache_mixin.py')"
10,pull_request_commit_comment,1366,nilearn,nilearn,KamalakerDadi,2017-01-27 13:29:30,"May prefer to denote ""str"" rather than string since you denote integer as int below. For the sake of consistency.",61b0221adf07ea8e96a78c271eb92466f23728b8,"(9, '', u'nilearn/_utils/cache_mixin.py')"
11,pull_request_commit,1366,nilearn,nilearn,ahoyosid,2017-01-25 14:51:49,adding _check_memory function,3da1510c6c5de5a831cd37364d36d011035b5352,
12,pull_request_commit,1366,nilearn,nilearn,ahoyosid,2017-01-25 15:01:18,checking memory in check_embedded_nifti_masker,765500f054161cdcea267ab6b8d7cd466cc50c75,
13,pull_request_commit,1366,nilearn,nilearn,ahoyosid,2017-01-25 15:27:02,adding test function,e3d2a80fa6d469a81f094f2c8be99bf951a5a1bb,
14,pull_request_commit,1366,nilearn,nilearn,ahoyosid,2017-01-25 21:21:44,adding brief comment on _check_memory,ab1d5cbd4bbb808518395e23137e42f8aece5bcc,
15,pull_request_commit,1366,nilearn,nilearn,ahoyosid,2017-01-26 15:32:16,adding doc,580af72cd98d64105d03809aaba21e64bd1b00a0,
16,pull_request_commit,1366,nilearn,nilearn,ahoyosid,2017-01-26 16:39:44,"adding None, docstring",61b0221adf07ea8e96a78c271eb92466f23728b8,
0,rectype,issueid,project_owner,project_name,actor,time,text,action,title
1,issue_title,1301,nilearn,nilearn,jehane,2016-10-02 10:28:12,"Accentuated characters are creating build failures with python3 (during rpmbuild)
",start issue,Removing accentuated characters
2,issue_closed,1301,nilearn,nilearn,GaelVaroquaux,2017-01-19 10:23:12,,closed issue,Removing accentuated characters
3,pull_request_title,1301,nilearn,nilearn,jehane,2016-10-02 10:28:12,"Accentuated characters are creating build failures with python3 (during rpmbuild)
",856975bd751e3d1eb1bb0938f67b6f5c0b859a03,Removing accentuated characters
4,pull_request_merged,1301,nilearn,nilearn,GaelVaroquaux,2017-01-19 10:23:12,Removing accentuated characters,d1452a9df68a7d39ed7b9269c47d8750898ad370,Pull request merge from jehane/nilearn:master to nilearn/nilearn:master
5,issue_comment,1301,nilearn,nilearn,GaelVaroquaux,2017-01-19 10:23:08,Merging this. It's simple,,
6,issue_comment,1301,nilearn,nilearn,mscherer,2016-10-02 11:12:24,"I think the removal of accentuaed characters are not the right fix, but getting code dealing with unicode on python2 and 3 can be a bit complex.
",,
7,issue_comment,1301,nilearn,nilearn,mscherer,2016-10-02 11:30:29,"So I found out that I can't reproduce the issue with:

```
python3 setup.py 
```

but if I do:

```
 LC_ALL=C python3 setup.py build
```

it result into:

```
Traceback (most recent call last):
  File ""setup.py"", line 36, in <module>
    _VERSION_GLOBALS = load_version()
  File ""setup.py"", line 22, in load_version
    exec(fp.read(), globals_dict)
  File ""/usr/lib64/python3.5/encodings/ascii.py"", line 26, in decode
    return codecs.ascii_decode(input, self.errors)[0]
UnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 116: ordinal not in range(128)
```
",,
8,pull_request_commit,1301,nilearn,nilearn,jehane,2016-10-02 10:24:32,"Update README.rst

Remove accentued character causing a rpmbuild failure for python3",2850b3601cc23f4b22d197a15a46e8c0f3c18ab1,
9,pull_request_commit,1301,nilearn,nilearn,jehane,2016-10-02 10:26:06,"Update version.py

Removing accentuated characters who create a build failure with python3",856975bd751e3d1eb1bb0938f67b6f5c0b859a03,
0,rectype,issueid,project_owner,project_name,actor,time,text,action,title
1,issue_title,1335,nilearn,nilearn,alexsavio,2016-12-06 14:46:18,A third try for #1295,start issue,[MRG+1] Add fetcher for Allen 2011 RSN fMRI atlas
2,issue_closed,1335,nilearn,nilearn,GaelVaroquaux,2017-01-22 10:23:33,,closed issue,[MRG+1] Add fetcher for Allen 2011 RSN fMRI atlas
3,pull_request_title,1335,nilearn,nilearn,alexsavio,2016-12-06 14:46:18,A third try for #1295,5b968b86d24fd1c5d1267caebf3f78dfdbff3013,[MRG+1] Add fetcher for Allen 2011 RSN fMRI atlas
4,pull_request_merged,1335,nilearn,nilearn,GaelVaroquaux,2017-01-22 10:23:33,[MRG+1] Add fetcher for Allen 2011 RSN fMRI atlas,73829ff02b1df9c2260d67d36425269d3ca815d4,Pull request merge from Neurita/nilearn:rsn_fetch3 to nilearn/nilearn:master
5,issue_comment,1335,nilearn,nilearn,alexsavio,2016-12-07 10:38:01,Could you please merge this? I have copied the code from previous PRs and fixed docstring style for Sphinx. It's the same material as before but with cleaner history.,,
6,issue_comment,1335,nilearn,nilearn,alexsavio,2017-01-21 12:34:25,"I will look into this later today.

On Sat, 21 Jan 2017, 12:03 Gael Varoquaux, <notifications@github.com> wrote:

> @alexsavio <https://github.com/alexsavio> : you do have a legit test
> failure that needs to be fixed.
>
> After that: +1 for merge.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/nilearn/nilearn/pull/1335#issuecomment-274254790>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/ACW4jEs8L-j-jZ3KlcXvL1YF-55g7kBuks5rUeXwgaJpZM4LFfH4>
> .
>
-- 

Sent from my phone, sorry for brevity or typos.
",,
7,pull_request_commit_comment,1335,nilearn,nilearn,KamalakerDadi,2016-12-10 05:07:03,"Sorry, if I miss this earlier. You can do only ```:func:nilearn.datasets.fetch_atlas_allen_2001```

Since you already have initialized in atlas.py",5b968b86d24fd1c5d1267caebf3f78dfdbff3013,"(None, '', u'doc/whats_new.rst')"
8,pull_request_commit_comment,1335,nilearn,nilearn,KamalakerDadi,2016-12-10 05:09:03,"Either we stick to ```string``` or ```str```. Some are specified as ```bool``` rather than ```boolean```.

I will prefer shortcuts ```str```",5b968b86d24fd1c5d1267caebf3f78dfdbff3013,"(None, '', u'nilearn/datasets/atlas.py')"
9,pull_request_commit_comment,1335,nilearn,nilearn,KamalakerDadi,2016-12-10 05:16:52,"May be we ""indent"" these return lines so that it appears like in the snapshot when we build the documentation.

![allen_return](https://cloud.githubusercontent.com/assets/11410385/21071427/30916b40-bea0-11e6-90e1-8f9485a63699.png)

",5b968b86d24fd1c5d1267caebf3f78dfdbff3013,"(None, '', u'nilearn/datasets/atlas.py')"
10,pull_request_commit_comment,1335,nilearn,nilearn,KamalakerDadi,2016-12-10 06:19:59,"Also, ""aggregate_ic_comps"" and ""all_unthresh_tmaps"" has both of 75 components.
What is the difference ?",5b968b86d24fd1c5d1267caebf3f78dfdbff3013,"(None, '', u'nilearn/datasets/atlas.py')"
11,pull_request_commit_comment,1335,nilearn,nilearn,KamalakerDadi,2016-12-10 06:21:11,"It looks like labels are not ordered. Isn't it ?

Are these collected from data resource ?",5b968b86d24fd1c5d1267caebf3f78dfdbff3013,"(None, '', u'nilearn/datasets/atlas.py')"
12,pull_request_commit_comment,1335,nilearn,nilearn,KamalakerDadi,2016-12-10 06:23:04,content name looks wrong. What we want is 'rsn_unthresh_tmaps'. Isn't it?,5b968b86d24fd1c5d1267caebf3f78dfdbff3013,"(None, '', u'nilearn/datasets/description/allen_rsn_2011.rst')"
13,pull_request_commit_comment,1335,nilearn,nilearn,alexsavio,2016-12-12 11:13:25,"no, the indices are for the `all_unthresh_tmaps` file. in the `rsn_unthresh_tmaps` file these have a different order and explained in the cited paper. rsn_unthresh_tmaps is a subset of all_unthresh_tmaps. I see the confusion, however this is how the information and files are available from the source.",5b968b86d24fd1c5d1267caebf3f78dfdbff3013,"(None, '', u'nilearn/datasets/description/allen_rsn_2011.rst')"
14,pull_request_commit_comment,1335,nilearn,nilearn,alexsavio,2016-12-12 11:15:48,"I could order the label lists, this is how they are ordered in the paper:
http://mialab.mrn.org/data/hcp/2011_Allen_FN_RestingBaseline.pdf",5b968b86d24fd1c5d1267caebf3f78dfdbff3013,"(None, '', u'nilearn/datasets/atlas.py')"
15,pull_request_commit_comment,1335,nilearn,nilearn,alexsavio,2016-12-12 11:19:50,"I am not sure. The maps are very similar, but the values are different. The description page does not help: http://mialab.mrn.org/data/index.html",5b968b86d24fd1c5d1267caebf3f78dfdbff3013,"(None, '', u'nilearn/datasets/atlas.py')"
16,pull_request_commit_comment,1335,nilearn,nilearn,alexsavio,2016-12-12 14:45:25,"Agreed, I will fix this.",5b968b86d24fd1c5d1267caebf3f78dfdbff3013,"(None, '', u'nilearn/datasets/atlas.py')"
17,pull_request_commit_comment,1335,nilearn,nilearn,alexsavio,2016-12-12 14:45:28,"Agreed, I will fix this.",5b968b86d24fd1c5d1267caebf3f78dfdbff3013,"(None, '', u'doc/whats_new.rst')"
18,pull_request_commit_comment,1335,nilearn,nilearn,GaelVaroquaux,2017-01-19 10:10:55,"@alexsavio : sorry for the long turn around. I am doing too many things, and as a result I become a bottleneck.

It would be good if we could try to be as close as possible to the structure of the other atlases that we are downloading. In particular, it would be good if the maps that are most likely to be used would be in a key called ""maps"", as in the other atlases, and the labels in a list given the corresponding labels in the order of the maps. You would have to give names to maps, rather than networks, but that should be easy, for instance ""Default-Mode_50"", .... You would need to add a list of networks labels too. The names of the other maps could then use a similar terminology, such as ""unthresh_maps"""", and ""networks_maps"".

The msdl atlas, for instance, exposes this structure. In the beginning, we weren't very good at imposing this structure, but while teaching we saw that it led to unneeded conceptual difficulties for the users.",5b968b86d24fd1c5d1267caebf3f78dfdbff3013,"(None, '', u'nilearn/datasets/atlas.py')"
19,pull_request_commit_comment,1335,nilearn,nilearn,alexsavio,2017-01-19 16:11:12,@GaelVaroquaux thanks for your comments.,5b968b86d24fd1c5d1267caebf3f78dfdbff3013,"(None, '', u'nilearn/datasets/atlas.py')"
20,pull_request_commit_comment,1335,nilearn,nilearn,KamalakerDadi,2017-01-21 16:32:16,components -> comps or vice-versa. In Returns documentation you have written as comps.,5b968b86d24fd1c5d1267caebf3f78dfdbff3013,"(None, '', u'nilearn/datasets/atlas.py')"
21,pull_request_commit_comment,1335,nilearn,nilearn,KamalakerDadi,2017-01-21 16:33:20,description doc is missing in Returns section.,5b968b86d24fd1c5d1267caebf3f78dfdbff3013,"(32, '', u'nilearn/datasets/atlas.py')"
22,pull_request_commit_comment,1335,nilearn,nilearn,KamalakerDadi,2017-01-21 16:36:21,"You missed to change here to ""maps"", ""rsn28"", ""comps"", I guess. Can you please have a look ?",5b968b86d24fd1c5d1267caebf3f78dfdbff3013,"(None, '', u'nilearn/datasets/tests/test_atlas.py')"
23,pull_request_commit,1335,nilearn,nilearn,alexsavio,2016-12-06 14:43:35,add fetcher for Allen 2011 RSN fMRI atlas,39548d0ef4c6097d4c71ade2a4eaac9d096b1ff8,
24,pull_request_commit,1335,nilearn,nilearn,alexsavio,2016-12-06 17:23:42,fix docstring indentation,7fefc940049ef60e5b38cdf1ceae07b9823b596f,
25,pull_request_commit,1335,nilearn,nilearn,alexsavio,2016-12-07 10:06:51,fix docstring style for happy Sphinx,a327f5ba5fe6157666bdafc6cad654e2d3b9699b,
26,pull_request_commit,1335,nilearn,nilearn,alexsavio,2016-12-14 13:45:02,small documentation fixes,e04e916c7c61781016390834530267f8c1e4bdd5,
27,pull_request_commit,1335,nilearn,nilearn,alexsavio,2017-01-19 17:03:33,change the labels of the allen atlas dataset,68e3699215df53a6bd57675c75d937f2d3a75891,
28,pull_request_commit,1335,nilearn,nilearn,alexsavio,2017-01-19 18:01:26,Add Allen atlas to plot_prob_atlas example,cdc336e7fb9aaf345b8573cd009ef7044f422554,
29,pull_request_commit,1335,nilearn,nilearn,GaelVaroquaux,2017-01-21 10:50:40,Merge branch 'master' into rsn_fetch3,9e8ef7e5e0fbef8ff2964a5b315bf92d5748765b,
30,pull_request_commit,1335,nilearn,nilearn,alexsavio,2017-01-21 21:27:56,fix atlas allen_2011 dataset key names,5b968b86d24fd1c5d1267caebf3f78dfdbff3013,
0,rectype,issueid,project_owner,project_name,actor,time,text,action,title
1,issue_title,1363,nilearn,nilearn,SunilKalmady,2017-01-24 03:49:57,"I am trying to use NiftiLabelsMasker with an atlas and image (data) of different affine matrix.  I get very different time series when I set resampling_target = ""labels"" vs  resampling_target = ""data"".  Why does this happen?

from nilearn.input_data import NiftiLabelsMasker
masker = NiftiLabelsMasker(labels_img=atlas_filename, standardize=""true"",
                         verbose=5, resampling_target = ""labels"")
    
masker = NiftiLabelsMasker(labels_img=atlas_filename, standardize=""true"",
                           verbose=5, resampling_target = ""data"")

time_series = masker.fit_transform(fmri_filenames)

I believe I get correct results only when I set resampling_target = ""labels"", but this takes longer time.
Is it due to following warning ? -

> C:\Program Files\Anaconda3\lib\site-packages\scipy\ndimage\interpolation.py:430: UserWarning: The behaviour of affine_transform with a one-dimensional array supplied for the matrix parameter has changed in scipy 0.18.0.

I am using the most recent version of nilearn downloaded from github. Thanks.",start issue,Resampling error? - The behaviour of affine_transform with a one-dimensional array supplied for the matrix parameter has changed in scipy 0.18.0.
2,issue_closed,1363,nilearn,nilearn,GaelVaroquaux,2017-02-03 06:02:26,,closed issue,Resampling error? - The behaviour of affine_transform with a one-dimensional array supplied for the matrix parameter has changed in scipy 0.18.0.
3,issue_comment,1363,nilearn,nilearn,cancan101,2017-11-02 22:07:08,You can suppress this error like so: https://github.com/scipy/scipy/commit/d4aaed4a64682c331a6f87386e28f5b1784be2be.,,
0,rectype,issueid,project_owner,project_name,actor,time,text,action,title
1,issue_title,1309,nilearn,nilearn,dillonplunkett,2016-10-12 19:45:08,"Implements fix proposed at #1308 
",start issue,make concat_niimgs preserve header info
2,issue_closed,1309,nilearn,nilearn,GaelVaroquaux,2017-01-19 10:48:59,,closed issue,make concat_niimgs preserve header info
3,pull_request_title,1309,nilearn,nilearn,dillonplunkett,2016-10-12 19:45:08,"Implements fix proposed at #1308 
",c23b054a28bf6e7d6f3038631d77b794104b959e,make concat_niimgs preserve header info
4,pull_request_merged,1309,nilearn,nilearn,GaelVaroquaux,2017-01-19 10:48:59,make concat_niimgs preserve header info,e2cccb4c223156583d1665db65191d2ccc04b2cb,Pull request merge from dillonplunkett/nilearn:concat_header to nilearn/nilearn:master
5,issue_comment,1309,nilearn,nilearn,GaelVaroquaux,2017-01-19 10:48:54,LGTM. Thank you. Merging.,,
6,pull_request_commit,1309,nilearn,nilearn,dillonplunkett,2016-10-12 19:42:53,make concat_niimgs preserve header info,c23b054a28bf6e7d6f3038631d77b794104b959e,
0,rectype,issueid,project_owner,project_name,actor,time,text,action,title
1,issue_title,1365,nilearn,nilearn,ahoyosid,2017-01-25 14:33:44,"I'm trying to use the check_embedded_nifti_maskfer from masker_validation, instead of #1351.
However, I'm having some troubles as all the maskers use memory=Memory(cachedir=None).

For example: 
```
from nilearn.input_data.masker_validation import check_embedded_nifti_masker

class Toto(object):
    def __init__(self, **kwargs):
        for k, v in kwargs.items():
            setattr(self, k, v)

    def fit(self, X, *args, **kwargs):
        self.masker_ = check_embedded_nifti_masker(self, multi_subject=False)
        self.masker_.fit(X)

from nilearn.datasets import fetch_haxby
dataset = fetch_haxby(n_subjects=1)

from sklearn.externals.joblib import Memory
# case 1: works like a charm
toto1 = Toto(memory=Memory(cachedir=None), memory_level=1, verbose=False)
toto1.fit(dataset.func[0])

# case 2: it breaks as toto has no attribute cachedir
toto2 = Toto(memory=None, memory_level=1, verbose=False)
toto2.fit(dataset.func[0])
```
In the second case, 
AttributeError: 'NoneType' object has no attribute 'cachedir'

One possible solution is to leave only memory=None in the __init__, and doing the validation somewhere else.

Note: I suppose this goes the same direction as #1066  ",start issue,check_embedded_nifti_masker assumes a cachedir attribute
2,issue_closed,1365,nilearn,nilearn,ahoyosid,2017-02-23 10:55:56,,closed issue,check_embedded_nifti_masker assumes a cachedir attribute
0,rectype,issueid,project_owner,project_name,actor,time,text,action,title
1,issue_title,1369,nilearn,nilearn,ahoyosid,2017-01-27 15:10:52,"Minor changes in the docstring.
Wrong verbose, better description of the _check_memory function.",start issue,[DOC] improving docstring of _check_memory function
2,issue_closed,1369,nilearn,nilearn,bthirion,2017-01-27 20:45:27,,closed issue,[DOC] improving docstring of _check_memory function
3,pull_request_title,1369,nilearn,nilearn,ahoyosid,2017-01-27 15:10:52,"Minor changes in the docstring.
Wrong verbose, better description of the _check_memory function.",0c7d4e88f65da2a22bb38ecffd24d0b1a162d2fd,[DOC] improving docstring of _check_memory function
4,pull_request_merged,1369,nilearn,nilearn,bthirion,2017-01-27 20:45:27,[DOC] improving docstring of _check_memory function,23bd270898d21a607f00ab5de1322c14691fcacc,Pull request merge from ahoyosid/nilearn:check_memory_doc to nilearn/nilearn:master
5,pull_request_commit,1369,nilearn,nilearn,ahoyosid,2017-01-27 15:10:29,improving docstring,0c7d4e88f65da2a22bb38ecffd24d0b1a162d2fd,
