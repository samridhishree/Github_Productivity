"rectype","issueid","project_owner","project_name","actor","time","text","action","title"
"issue_title","989","nilearn","nilearn","KamalakerDadi","2016-02-14 14:43:24","- Added function `fetch_cobre_niak`, documentation, tests, reference

This function downloads current version of datasets  from download link as posted in Issue #915 

Still to add: `whatsnew` and any comments or improvements.
","start issue","[MRG+1] Datasets: Downloader for COBRE data"
"issue_closed","989","nilearn","nilearn","AlexandreAbraham","2016-02-17 09:02:01","","closed issue","[MRG+1] Datasets: Downloader for COBRE data"
"pull_request_title","989","nilearn","nilearn","KamalakerDadi","2016-02-14 14:43:24","- Added function `fetch_cobre_niak`, documentation, tests, reference

This function downloads current version of datasets  from download link as posted in Issue #915 

Still to add: `whatsnew` and any comments or improvements.
","cc4dd733a9a7ea24f7004f2f1228abcdf338f5c2","[MRG+1] Datasets: Downloader for COBRE data"
"pull_request_merged","989","nilearn","nilearn","AlexandreAbraham","2016-02-17 09:02:01","[MRG+1] Datasets: Downloader for COBRE data","32fa3e6e39ec90ca329d48789bce5b9398c8652c","Pull request merge from KamalakerDadi/nilearn:cobre_downloader to nilearn/nilearn:master"
"issue_comment","989","nilearn","nilearn","GaelVaroquaux","2016-02-14 17:06:01","Maybe the function should be called ""fetch_cobre"", and we'll later add an
option to decide between different preprocessing (niak or otherwise).
","",""
"issue_comment","989","nilearn","nilearn","KamalakerDadi","2016-02-16 10:10:23","Can somebody review this PR ? As we need this for Brain Hack. Thanks
","",""
"issue_comment","989","nilearn","nilearn","aabadie","2016-02-16 10:48:25","LGTM +1, The failing test on travis is not related to your PR (#986 was entered for this). Once CircleCI is done, we can merge this.
","",""
"issue_comment","989","nilearn","nilearn","GaelVaroquaux","2016-02-17 06:41:32","LGTM. :+1: for merge
","",""
"pull_request_commit_comment","989","nilearn","nilearn","aabadie","2016-02-14 15:42:57","This line and the one above don't work on python 3, you should use `decode()` in `i` because it's a byte string :

``` python
func_filenames = [('fmri_' + i.decode().strip(' ""\'') 
```
","cc4dd733a9a7ea24f7004f2f1228abcdf338f5c2","(None, '', u'nilearn/datasets/func.py')"
"pull_request_commit_comment","989","nilearn","nilearn","KamalakerDadi","2016-02-14 15:59:19","Thanks. I thought its `encode()`. Is it not ?
","cc4dd733a9a7ea24f7004f2f1228abcdf338f5c2","(None, '', u'nilearn/datasets/func.py')"
"pull_request_commit_comment","989","nilearn","nilearn","KamalakerDadi","2016-02-14 16:00:42","Could you point me any documentation to find this difference ? If you have any ?
","cc4dd733a9a7ea24f7004f2f1228abcdf338f5c2","(None, '', u'nilearn/datasets/func.py')"
"pull_request_commit_comment","989","nilearn","nilearn","aabadie","2016-02-14 16:10:49","I'm not sure it will work work with `encode()`. `np.recfromcsv` returns an array with `numpy._bytes`. Those only have a `decode()` method.
You can see in the code another place with the same trick : https://github.com/nilearn/nilearn/blob/master/nilearn/datasets/func.py#L1155
where `pheno` contains the result of `np.recfromcsv`.
","cc4dd733a9a7ea24f7004f2f1228abcdf338f5c2","(None, '', u'nilearn/datasets/func.py')"
"pull_request_commit_comment","989","nilearn","nilearn","AlexandreAbraham","2016-02-16 13:16:47","I thought that we had a version without scrubbing?
","cc4dd733a9a7ea24f7004f2f1228abcdf338f5c2","(72, '', u'nilearn/datasets/description/cobre.rst')"
"pull_request_commit_comment","989","nilearn","nilearn","AlexandreAbraham","2016-02-16 13:18:21","The individual files are available, why do we rely on an aggregation of them?
","cc4dd733a9a7ea24f7004f2f1228abcdf338f5c2","(None, '', u'nilearn/datasets/func.py')"
"pull_request_commit_comment","989","nilearn","nilearn","AlexandreAbraham","2016-02-16 13:19:03","Isn't that a bit dangerous for reproducibility?
","cc4dd733a9a7ea24f7004f2f1228abcdf338f5c2","(None, '', u'nilearn/datasets/func.py')"
"pull_request_commit_comment","989","nilearn","nilearn","AlexandreAbraham","2016-02-16 13:20:03","`mat` files cannot be processed by nilearn. Should we load them or add some code to process them automatically (can be another PR).
","cc4dd733a9a7ea24f7004f2f1228abcdf338f5c2","(97, '', u'nilearn/datasets/func.py')"
"pull_request_commit_comment","989","nilearn","nilearn","KamalakerDadi","2016-02-16 13:27:25","Yes, but as Pierre said in the issue that it will take time and we decided to proceed with this version. 
","cc4dd733a9a7ea24f7004f2f1228abcdf338f5c2","(72, '', u'nilearn/datasets/description/cobre.rst')"
"pull_request_commit_comment","989","nilearn","nilearn","KamalakerDadi","2016-02-16 13:28:07","I didn't get your comment. I thought you understand the situation to download each individual file.
","cc4dd733a9a7ea24f7004f2f1228abcdf338f5c2","(None, '', u'nilearn/datasets/func.py')"
"pull_request_commit_comment","989","nilearn","nilearn","KamalakerDadi","2016-02-16 13:29:50","which one `random_state=0` ?
","cc4dd733a9a7ea24f7004f2f1228abcdf338f5c2","(None, '', u'nilearn/datasets/func.py')"
"pull_request_commit_comment","989","nilearn","nilearn","AlexandreAbraham","2016-02-16 13:44:46","OK!
","cc4dd733a9a7ea24f7004f2f1228abcdf338f5c2","(72, '', u'nilearn/datasets/description/cobre.rst')"
"pull_request_commit_comment","989","nilearn","nilearn","AlexandreAbraham","2016-02-16 13:46:35","Well, GaÃ«l said in the issue that a 1 hour download was too much. Plus it does not make sense to return 10 subjects by default if you force downloading the whole dataset. But nevermind, let's move on.
","cc4dd733a9a7ea24f7004f2f1228abcdf338f5c2","(None, '', u'nilearn/datasets/func.py')"
"pull_request_commit_comment","989","nilearn","nilearn","AlexandreAbraham","2016-02-16 13:48:02","`random_state=0` may give different results depending on the machine used. If subjects are splitted controls/schizophrenic, maybe we should just take the first `n_subjects/2` controls and the first `n_subject/2` schizos?
","cc4dd733a9a7ea24f7004f2f1228abcdf338f5c2","(None, '', u'nilearn/datasets/func.py')"
"pull_request_commit_comment","989","nilearn","nilearn","KamalakerDadi","2016-02-16 17:00:40","> Should we load them or add some code to process them automatically (can be another PR).

I will keep it open to matlab users for example. I don't think we need to load them.
","cc4dd733a9a7ea24f7004f2f1228abcdf338f5c2","(97, '', u'nilearn/datasets/func.py')"
"pull_request_commit_comment","989","nilearn","nilearn","KamalakerDadi","2016-02-17 06:38:27","Done. Can you see it is Ok ?
","cc4dd733a9a7ea24f7004f2f1228abcdf338f5c2","(None, '', u'nilearn/datasets/func.py')"
"pull_request_commit","989","nilearn","nilearn","KamalakerDadi","2016-02-14 14:37:25","Datasets: Downloader for COBRE data
- Added function, documentation, tests, reference","b2431ce513791fc94021397d6f126405ecdb9047",""
"pull_request_commit","989","nilearn","nilearn","KamalakerDadi","2016-02-16 09:36:15","Fixing travis py35 failures and name chnaged to fetch_cobre","57839e26fd4cd1d9245963e45fdc477fac6c6ab1",""
"pull_request_commit","989","nilearn","nilearn","KamalakerDadi","2016-02-16 09:58:32","Fixing python 35 compatibility failures","4bede95e7881470c59a0abfc76a7c885bdbcdfb7",""
"pull_request_commit","989","nilearn","nilearn","KamalakerDadi","2016-02-16 21:57:37","Datasets structure link and comments","a9f9c5e31b8e55098e980f2e3fbfd80a43fabfc1",""
"pull_request_commit","989","nilearn","nilearn","KamalakerDadi","2016-02-16 22:15:04","Fixing python 35 failure","cc4dd733a9a7ea24f7004f2f1228abcdf338f5c2",""
