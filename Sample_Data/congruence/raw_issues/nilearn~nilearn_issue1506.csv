"rectype","issueid","project_owner","project_name","actor","time","text","action","title"
"issue_title","1506","nilearn","nilearn","GaelVaroquaux","2017-09-07 19:29:25","The images from the following paper:
http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1002180
are available on
https://neurovault.org/collections/503/
and on
http://neurovault.org/collections/504/
and the emotion and pain ratings are available as meta data.

We could build an example that decodes emotion or pain using the neurovault dowloader. It would be super cool because it would add a decoding example with a different dataset (everybody is bored of Haxby, and the Jimura doesn't work well.","start issue","New dataset and example for decoding data"
"issue_comment","1506","nilearn","nilearn","bthirion","2017-11-20 22:36:04","Great proposition !
","",""
"issue_comment","1506","nilearn","nilearn","nicofarr","2017-11-16 15:48:43","I'm happy to try out this one. 
I'll try do some first tests on the smallest one (collection 504) although it's only 28 subjects with three pain ratings, and see whether it's worth doing a full nilearn example from there. ","",""
"issue_comment","1506","nilearn","nilearn","nicofarr","2017-11-18 04:57:02","First straightforward decoding example for 503 is [here](http://nbviewer.jupyter.org/gist/nicofarr/d73c8f611c0a77d4e989b11ae4a4033a) :  

And [here](http://nbviewer.jupyter.org/gist/nicofarr/1b0bccf636aa2a1c82ed7f07b528ea64) for 504. 

In both cases, a very straightforward decoding approach seems to yield acceptable results. 

I'll focus on collection 503 as it's the one that yields the largest number of images. 
A few things : 

- In the notebook above, I've randomly taken 700 images out of the 5000+ images availables, without controlling for anything. I didn't control for subjects. 

- It seems there are more examples for Rating 1 than the other ratings. 

- I also didn't take into account the train/test split that is present in the metadata, but rather I used 5-fold CV. 

- On 700 images, when training to classify Rating 1 vs Rating 5, we obtain a CV-accuracy of about 81% over folds. I've tried with 500 images and obtained a similar result. 



Suggestions regarding where to go from here : 
- Implement an example with the full regression over the rating values (using Lasso as in the paper ? ) 
- Implement an example with Searchlight 
- Implement an example with SpaceNetClassifier / SpaceNetRegressor 
- Generate a smaller list of images that correspond a subset of subjects and feed it to the Neurovault fetcher, so that the example doesn't download the 5000+ images

Any thoughts ? 


","",""
"issue_comment","1506","nilearn","nilearn","ljchang","2017-09-07 19:43:38","Great idea!  I'm happy to help contribute.  Here is a [start](https://github.com/Summer-MIND/mind_2017/blob/master/Tutorials/Decoding/Chang_Decoding.ipynb) using a different toolbox.  ","",""
