"rectype","issueid","project_owner","project_name","actor","time","text","action","title"
"issue_title","1028","nilearn","nilearn","mjboos","2016-02-27 12:14:58","This is the encoding example for the Miyawaki et al., 2008 dataset, made at the Brainhack in Paris with @GaelVaroquaux 
","start issue","Encoding example"
"issue_closed","1028","nilearn","nilearn","GaelVaroquaux","2016-03-03 10:49:07","","closed issue","Encoding example"
"pull_request_title","1028","nilearn","nilearn","mjboos","2016-02-27 12:14:58","This is the encoding example for the Miyawaki et al., 2008 dataset, made at the Brainhack in Paris with @GaelVaroquaux 
","463dc2ab4d17fd7456b7677a1638237be075bc0e","Encoding example"
"pull_request_merged","1028","nilearn","nilearn","GaelVaroquaux","2016-03-03 10:49:07","Encoding example","2596a0d639b3863f098f87c75b5bbee9c3e25165","Pull request merge from mjboos/nilearn:encoding_example to nilearn/nilearn:master"
"issue_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-28 16:47:53","Unless I missed a few more PEP8 errors, I think that I have made all my comments. So this is definitely almost there.

By the way: the current status of rendered doc can be seen on:
https://circle-artifacts.com/gh/nilearn/nilearn/1344/artifacts/0/home/ubuntu/nilearn/doc/_build/html/auto_examples/02_decoding/plot_miyawaki_encoding.html
","",""
"issue_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-03-02 21:51:44","Looks great. I am +1 for merge.

Just to be sure that everything is right, I have restarted the CircleCI build after clearing the cache, as the downloaded dataset wasn't the latest.
","",""
"issue_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-03-03 10:40:59","@KamalakerDadi : I started the build again to try to refresh the cache. Indeed on CircleCI the rendering is wrong because of a caching problem, as it is still grabbing the broken brain mask.

Anyhow, I ran this on my computer and everything looks right.

Hence, I am +1 for merge.

There is one little thing, which is that the example runs for 10mn. We'd like to make this faster, as 10mn is quite a dent in our budget with regards to compute time for all the examples. I am playing a bit with the various estimators locally to see if I can make things faster.
","",""
"issue_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-03-03 10:49:02","OK, I remove my previous comment: the example is quite fast, the time was mostly due to the download time. So am merging this. Thank you very much @mjboos !
","",""
"issue_comment","1028","nilearn","nilearn","mjboos","2016-02-28 19:55:10","Huh, there are still red backgrounds of the marked voxels in the rendered doc at: https://circle-artifacts.com/gh/nilearn/nilearn/1346/artifacts/0/home/ubuntu/nilearn/doc/_build/html/auto_examples/02_decoding/plot_miyawaki_encoding.html

But there shouldn't be, the scores of the marked voxels are >.45, and should be bright yellow for this colormap. I cannot reproduce this on my machine (or on another when I clone the repo), for me the voxels have the correct color for their score.

Any idea why it looks different with circle-ci?
","",""
"issue_comment","1028","nilearn","nilearn","KamalakerDadi","2016-03-03 09:05:42","@GaelVaroquaux Have you started the build again ? What was wrong in last build ? I could not catch.
","",""
"issue_comment","1028","nilearn","nilearn","KamalakerDadi","2016-03-03 10:46:22","> Anyhow, I ran this on my computer and everything looks right.

Great. I have no other comments. Except that I think this example deserves place in Userguide module ?
","",""
"issue_comment","1028","nilearn","nilearn","KamalakerDadi","2016-03-03 10:50:00","Great work @mjboos 
","",""
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-27 12:51:19","In examples, we like to do the imports in the same ""cell"" as where we use the corresponding symbols: it makes it easier for beginner to relate the symbols to where they come from.
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-27 12:51:54",""": the data after the first twelve files""
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(45, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-27 12:52:44","Maybe we could plot one or two image here, and have a text reminding us that these were the stimuli.
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","aabadie","2016-02-27 12:54:01","MultiNiftiMas_k_er
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-27 12:56:55","Ah, maybe here is where we want to plot stimuli.

I would suggest moving the definition of y_shape here, to have things close to where they are understandable.
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-27 12:57:54","Can we not use scikit-learn's cross_val_score?
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-27 12:58:28","Sorry, stupid comment. It cross_val_predict that we would need. But it's only in very recent scikit-learn versions.
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-27 12:58:50","I wonder if, for Python beginners, a for loop wouldn't be easier to read.
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-27 12:59:44","Well, no, actually, we should be able to combine that cell with the one after and use cross_val_score, no?
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-27 13:00:15","PEP8: you need a space after ','
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-27 13:01:11","We like to call the return of plot_stat_map 'display'. I think that it reflects better the type of object that this is. Tell me if you disagree, though.
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-27 13:01:36","Do we need the ""symmetric_cbar=False""
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-27 13:02:51","Can you modify index_to_xy_coord so that it's return argument can be passed to add_markers with any transformation. It will make the example simpler.
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-27 13:03:16","PEP8: space after ','
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-27 13:08:47","Maybe you should say that this is partly reproducing the Miyawaki paper, from which the data comes from.
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-27 13:09:45","PEP8: space after coma

Also, any chance that you find a more explicit name for this variable?
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-27 13:09:58","PEP8: space after coma
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","mjboos","2016-02-27 22:01:29","I think cross_val_score needs a scorer that returns a single float, but we need an array of scores (one for each voxel). We could do cross_val_score independently for each voxel and then concatenate, but that makes the example much slower (7 minutes vs. 20 seconds for me)
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-28 16:29:23","In the examples, we tend to import modules in the cell where we need them, in order to have the imports as close as possible to the code that uses them.
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-28 16:31:06","PEP8 tells us that there should not be spaces before and after the ""="" next to ""multioutput.
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-28 16:33:17","Maybe we can merge that cell with the next one, and have only one for loop. The ""predictions"" list might then not be needed.
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-28 16:33:43","> I think cross_val_score needs a scorer that returns a single float, but
> we need an array of scores (one for each voxel). We could do
> cross_val_score independently for each voxel and then concatenate, but
> that makes the example much slower (7 minutes vs. 20 seconds for me)

Point taken.
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-28 16:35:58","We have a convention in nilearn to always end the names of the images with ""_img"". Would you mind changing  `score_map` to `score_img` and `thresholded_score_map` to `thresholded_score_img` ?
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-28 16:36:51","The 'show' should be only at the end of the file because in script mode it will block the execution of the script.
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-28 16:38:19","The red doesn't show, because the background is red. Maybe it's better to use cyan.
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-28 16:42:35","Maybe a line of comment on what is GridSpec.
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-28 16:43:24","Maybe a title for the figure?
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-28 16:45:35","PEP8 says that, in function calls, there should be no spaces before and after equal signs used for keyword-arguments (unlike equal signs used in assignments, outside the function calls.
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-28 16:45:51","PEP8 says that, in function calls, there should be no spaces before and after equal signs used for keyword-arguments (unlike equal signs used in assignments, outside the function calls.
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-28 16:46:03","PEP8 says that, in function calls, there should be no spaces before and after equal signs used for keyword-arguments (unlike equal signs used in assignments, outside the function calls.
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","mjboos","2016-02-28 17:58:10","Cyan doesn't have a nice Sequential colormap like 'Reds' or 'Blues' (and the ones containing cyan just don't look good here), building one makes the tutorial more complicated. I've switched the red and blue marker, so the contrast to the surrounding voxels is stronger. I find it discriminative enough, but I can also add a custom colormap if you think that's better.
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-28 18:08:44","> I've switched the red and blue marker, so the contrast to the
> surrounding voxels is stronger. I find it discriminative enough,

That sounds good!
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-29 08:30:26","I wonder if that figure isn't too tall: the aspect ratio should probably be around 3/2. Right now, it has a lot of whitespace at the bottom.
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-29 08:33:21","How about using cyan to be really robust to fluctuations in prediction power. (I am trying to understand why things vary across computers, but I haven't so far).
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-29 08:44:03","Nitpick: this might be written:

```
cut_score = np.mean(scores, axis=0)
```
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-29 08:45:42","We tend to prefer using masker.inverse_transform. Is there a reason why it is not suitable here?
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-29 08:49:19","I am stupid: you told me why no cyan: no corresponding colormap. It's before coffee, sorry.

How about black, then? You can use the gray colormap.
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-29 08:52:40","How about you add a 'vmax=.5' and see how it looks like on CircleCI. I suspect that outside the cuts there are some voxels that perform very well, and these are setting the max of the color range.

I've been staring at the code for a little while, and I still don't understand why it looks different on different computers :$.
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(174, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","banilo","2016-02-29 13:04:47","perhaps ""based on information of presented stimuli""
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","banilo","2016-02-29 13:06:43","grammar
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","banilo","2016-02-29 13:07:58","binary (i.e., X and Y values) image
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","banilo","2016-02-29 13:08:55","point at the end of this sentence
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","banilo","2016-02-29 13:10:22","perhaps use normal `#` instead
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(164, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","banilo","2016-02-29 13:12:30","can be simplified to `fig = plt.figure(figsize=(12, 12))`
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(186, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","mjboos","2016-02-29 15:44:03","Was just how the original code was. No problem to change
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","mjboos","2016-02-29 15:49:40","Didn't work for me. We need to get the figure object after it was created by plot_stat_map, giving it directly to it in the right size does not scale the colorbar correctly with the image.
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(186, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","eickenberg","2016-02-29 15:51:55","this looks a little shocking until you realize that `X` is the fMRI, not the design. It's fine if you follow the script properly. The other option would have been to name it `Y` and the pixels `X` to indicate the encoding direction `X --> Y`.
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","eickenberg","2016-02-29 15:53:09","Isn't it awesome that we have non-aggregated `r2_score` values accessible in sklearn? ;)
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-29 16:08:24","> this looks a little shocking until you realize that X is the fMRI, not the
> design. It's fine if you follow the script properly. The other option would
> have been to name it Y and the pixels X to indicate the encoding direction X
> --> Y.

Yes, actually. We could call them 'fmri_data', and 'stimuli'.
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","mjboos","2016-02-29 16:11:44","Makes sense. Right now it mimicks the preprocessing/data-loading of the reconstruction example, so you could see that it really just reverses X and y, but giving them expressive names would be much clearer.
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","mjboos","2016-02-29 18:27:15","Works now also on CircleCI. As @AlexandreAbraham pointed out, marker_color needed to be set, apparently it was being overridden by edgecolor/facecolor on my computer. Maybe different behavior in diff. matplotlib-versions.
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(174, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-29 19:37:41","> Works now also on CircleCI. As @AlexandreAbraham pointed out, marker_color
> needed to be set, apparently it was being overridden by edgecolor/facecolor on
> my computer.

Awesome! Great job to both of you!
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(174, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-29 19:40:27","One (last?) question: why are you using new_img_like, and not just the output of masker.inverse_transform(cut_score)?
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","mjboos","2016-02-29 19:49:33","The mask doesn't have the affine transform of the background image.
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-29 19:53:10","> The mask doesn't have the affine transform of the background image.

Hum... One of the two must be wrong, then. Don't you think? I can't
really see another explaination.
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","mjboos","2016-02-29 19:56:42","Actually, the mask's affine transform is just an identity matrix.
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","GaelVaroquaux","2016-02-29 20:00:53","> Actually, the mask's affine transform is just an identity matrix.

So it's wrong. We must fix it.

@AlexandreAbraham, any chance that you can grab the affine from the
background image and upload to nitrc a fixed version of the mask?
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","AlexandreAbraham","2016-03-02 09:24:02","On it.
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","AlexandreAbraham","2016-03-02 09:57:58","Done in PR #1038. Note that, unfortunately, you will have to erase manually your miyawaki2008 folder to force downloading.
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit_comment","1028","nilearn","nilearn","mjboos","2016-03-02 17:33:34","Great, thank you!
","463dc2ab4d17fd7456b7677a1638237be075bc0e","(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')"
"pull_request_commit","1028","nilearn","nilearn","mjboos","2016-02-27 12:05:07","Encoding example using the Miyawaki et al., 2008 dataset","4df8a7f8070e08c81d381da66496910ca4627645",""
"pull_request_commit","1028","nilearn","nilearn","mjboos","2016-02-27 12:09:48","Encoding example for Miyawaki dataset","2fb9da183a1eb58a8f49cae70e89df420fe60a78",""
"pull_request_commit","1028","nilearn","nilearn","mjboos","2016-02-27 22:05:24","Added plots of the stimuli, changed description and fixed pep8 violations","59442085239832e1e622d1ff390746666391c572",""
"pull_request_commit","1028","nilearn","nilearn","mjboos","2016-02-27 22:30:52","deleted symmetric cbar","d23cc93caf86845069055102a4080974ebc15fe5",""
"pull_request_commit","1028","nilearn","nilearn","mjboos","2016-02-28 00:08:45","rephrased description and comments","a383ede0b04d941b1b119be6c8e96dfa449da475",""
"pull_request_commit","1028","nilearn","nilearn","mjboos","2016-02-28 17:57:25","integrated comments","f9235a5b68b324eb93bfceefc68ab01529706c4e",""
"pull_request_commit","1028","nilearn","nilearn","mjboos","2016-02-29 15:42:24","Slight rephrasing, added marker_color argument","07a4c40ad2d9500d10d0392896ef026eb453fc37",""
"pull_request_commit","1028","nilearn","nilearn","mjboos","2016-02-29 16:32:39","changed variable names","3440fbfd920ca88492f35086820dcd6913bf36a7",""
"pull_request_commit","1028","nilearn","nilearn","mjboos","2016-03-02 18:39:45","using affine transform of mask","463dc2ab4d17fd7456b7677a1638237be075bc0e",""
